{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import linecache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.saved_model.load(\"../pretrained_model/saved_model_with_signatures\")\n",
    "\n",
    "model_signature_directory = '../pretrained_model/model_architecture.csv'\n",
    "\n",
    "if os.path.exists(model_signature_directory):\n",
    "    # Collecting signature details\n",
    "    signatures_data = []\n",
    "\n",
    "    # Iterate over each signature in the model\n",
    "    for key, signature in model.signatures.items():\n",
    "        # Initialize dictionaries for current signature's inputs and outputs\n",
    "        inputs_dict = {}\n",
    "        outputs_dict = {}\n",
    "\n",
    "        # Iterate over inputs and outputs, filling in the dictionaries\n",
    "        for input_key, input_val in signature.structured_input_signature[1].items():\n",
    "            inputs_dict[input_key] = str(input_val.dtype.name)\n",
    "\n",
    "        for output_key, output_val in signature.structured_outputs.items():\n",
    "            outputs_dict[output_key] = str(output_val.dtype.name)\n",
    "\n",
    "        # Append the current signature's details to the list\n",
    "        signatures_data.append({\n",
    "            \"Signature Key\": key,\n",
    "            \"Inputs\": inputs_dict,\n",
    "            \"Outputs\": outputs_dict\n",
    "        })\n",
    "\n",
    "    # Convert list of signature data into a DataFrame for visualization\n",
    "    df_signatures = pd.DataFrame(signatures_data)\n",
    "\n",
    "    df_inputs = df_signatures[\"Inputs\"].apply(pd.Series)\n",
    "    df_outputs = df_signatures[\"Outputs\"].apply(pd.Series)\n",
    "    df_expanded = pd.concat([df_signatures.drop(['Inputs', 'Outputs'], axis=1), df_inputs, df_outputs], axis=1)\n",
    "    df_expanded.to_csv(\"../pretrained_model/model_architecture.csv\", index=False)\n",
    "else:\n",
    "    df_expanded = pd.read_csv(model_signature_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Signature Key</th>\n",
       "      <th>embedding_sample</th>\n",
       "      <th>target_seq_len</th>\n",
       "      <th>inp_pos</th>\n",
       "      <th>target_pos</th>\n",
       "      <th>inp_embeddings</th>\n",
       "      <th>input_seq_len</th>\n",
       "      <th>input_stroke</th>\n",
       "      <th>pen</th>\n",
       "      <th>seq_len</th>\n",
       "      <th>stroke</th>\n",
       "      <th>pi</th>\n",
       "      <th>sigma</th>\n",
       "      <th>embedding_sample</th>\n",
       "      <th>mu</th>\n",
       "      <th>position_sample</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>decode_stroke</td>\n",
       "      <td>float32</td>\n",
       "      <td>int32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>float32</td>\n",
       "      <td>int32</td>\n",
       "      <td>float32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>predict_embedding</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>float32</td>\n",
       "      <td>float32</td>\n",
       "      <td>float32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>float32</td>\n",
       "      <td>float32</td>\n",
       "      <td>float32</td>\n",
       "      <td>float32</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>predict_position</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>float32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>float32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>float32</td>\n",
       "      <td>float32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>float32</td>\n",
       "      <td>float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>encode_stroke</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>int32</td>\n",
       "      <td>float32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>float32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>forward_pass</td>\n",
       "      <td>NaN</td>\n",
       "      <td>int32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>int32</td>\n",
       "      <td>float32</td>\n",
       "      <td>float32</td>\n",
       "      <td>int32</td>\n",
       "      <td>float32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>float32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Signature Key embedding_sample target_seq_len  inp_pos target_pos  \\\n",
       "0      decode_stroke          float32          int32      NaN        NaN   \n",
       "1  predict_embedding              NaN            NaN  float32    float32   \n",
       "2   predict_position              NaN            NaN  float32        NaN   \n",
       "3      encode_stroke              NaN            NaN      NaN        NaN   \n",
       "4       forward_pass              NaN          int32      NaN        NaN   \n",
       "\n",
       "  inp_embeddings input_seq_len input_stroke      pen seq_len   stroke  \\\n",
       "0            NaN           NaN          NaN  float32   int32  float32   \n",
       "1        float32           NaN          NaN      NaN     NaN      NaN   \n",
       "2        float32           NaN          NaN      NaN     NaN      NaN   \n",
       "3            NaN         int32      float32      NaN     NaN      NaN   \n",
       "4            NaN         int32      float32  float32   int32  float32   \n",
       "\n",
       "        pi    sigma embedding_sample       mu position_sample  \n",
       "0      NaN      NaN              NaN      NaN             NaN  \n",
       "1  float32  float32          float32  float32             NaN  \n",
       "2  float32  float32              NaN  float32         float32  \n",
       "3      NaN      NaN          float32      NaN             NaN  \n",
       "4      NaN      NaN          float32      NaN             NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_expanded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocesses raw drawings and get the right input format for `encode_stroke`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions to adjusts all drawings to have a consistent scale or size\n",
    "def get_bounding_box(drawing):\n",
    "    minx = 99999\n",
    "    miny = 99999\n",
    "    maxx = 0\n",
    "    maxy = 0\n",
    "\n",
    "    for s in drawing:\n",
    "      minx = min(minx, min(s[0]))\n",
    "      maxx = max(maxx, max(s[0]))\n",
    "      miny = min(miny, min(s[1]))\n",
    "      maxy = max(maxy, max(s[1]))\n",
    "    return (minx, miny, maxx, maxy)\n",
    "\n",
    "def size_normalization(drawing):\n",
    "  bb = get_bounding_box(drawing)\n",
    "  width, height = bb[2] - bb[0], bb[3] - bb[1]\n",
    "  offset_x, offset_y = bb[0], bb[1]\n",
    "  if height < 1e-6:\n",
    "    height = 1\n",
    "\n",
    "  size_normalized_drawing = [[[(x - offset_x) / height for x in stroke[0]],\n",
    "                              [(y - offset_y) / height for y in stroke[1]],\n",
    "                              [t for t in stroke[2]]]\n",
    "                             for stroke in drawing]\n",
    "\n",
    "  return size_normalized_drawing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to resample the ink to have uniform time steps\n",
    "# (Ensure that each point is separated by a constant time step)\n",
    "def resample_ink(drawing, timestep=20):\n",
    "    resampled_drawing = []\n",
    "    \n",
    "    for stroke in drawing:\n",
    "        # Initialize with the first point\n",
    "        resampled_stroke = [[stroke[0][0], stroke[1][0], stroke[2][0]]]  \n",
    "        \n",
    "        for i in range(1, len(stroke[0])):\n",
    "            x0, y0, t0 = stroke[0][i-1], stroke[1][i-1], stroke[2][i-1]\n",
    "            x1, y1, t1 = stroke[0][i], stroke[1][i], stroke[2][i]\n",
    "            distance = np.sqrt((x1 - x0)**2 + (y1 - y0)**2)\n",
    "            if distance == 0:\n",
    "                continue\n",
    "            else:\n",
    "                new_points = max(1, int(distance / timestep))\n",
    "                for j in range(1, new_points + 1):\n",
    "                    new_point = [x0 + j * (x1 - x0) / new_points,\n",
    "                                y0 + j * (y1 - y0) / new_points,\n",
    "                                t0 + j * (t1 - t0) / new_points]\n",
    "                    resampled_stroke.append(new_point)\n",
    "        \n",
    "        resampled_drawing.append(resampled_stroke)\n",
    "\n",
    "    return resampled_drawing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I try with the first drawing in quick_draw_Eiffel_Tower:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are totally 3 strokes in the sample drawing\n"
     ]
    }
   ],
   "source": [
    "ndjson_file_path = 'full_raw_The_Eiffel_Tower.ndjson'\n",
    "\n",
    "# Select the line to read as the sample drawing\n",
    "line_number = 12\n",
    "# Use linecache to get the specific line\n",
    "line = linecache.getline(ndjson_file_path, line_number).strip()\n",
    "# Parse the JSON content from the line\n",
    "selected_row = json.loads(line)\n",
    "\n",
    "sample_drawing = selected_row[\"drawing\"]\n",
    "print(f\"There are totally {len(sample_drawing)} strokes in the sample drawing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[146, 22, 17]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sequence length for each stroke\n",
    "[len(i[0]) for i in sample_drawing]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the drawing\n",
    "drawing_normalized = size_normalization(sample_drawing)\n",
    "drawing_resampled = resample_ink(drawing_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[0.0,\n",
       "   0.004319654427645789,\n",
       "   0.008639308855291577,\n",
       "   0.019438444924406047,\n",
       "   0.02591792656587473,\n",
       "   0.03455723542116631,\n",
       "   0.04319654427645788,\n",
       "   0.05183585313174946,\n",
       "   0.06047516198704104,\n",
       "   0.06911447084233262,\n",
       "   0.07775377969762419,\n",
       "   0.08639308855291576,\n",
       "   0.09503239740820735,\n",
       "   0.09935205183585313,\n",
       "   0.10367170626349892,\n",
       "   0.11447084233261338,\n",
       "   0.11879049676025918,\n",
       "   0.12526997840172785,\n",
       "   0.12958963282937366,\n",
       "   0.12958963282937366,\n",
       "   0.12958963282937366,\n",
       "   0.12958963282937366,\n",
       "   0.12958963282937366,\n",
       "   0.12742980561555076,\n",
       "   0.12742980561555076,\n",
       "   0.12742980561555076,\n",
       "   0.12526997840172785,\n",
       "   0.12095032397408208,\n",
       "   0.11879049676025918,\n",
       "   0.11447084233261338,\n",
       "   0.11231101511879049,\n",
       "   0.1079913606911447,\n",
       "   0.10367170626349892,\n",
       "   0.10367170626349892,\n",
       "   0.10151187904967603,\n",
       "   0.10151187904967603,\n",
       "   0.09935205183585313,\n",
       "   0.09503239740820735,\n",
       "   0.09287257019438445,\n",
       "   0.09071274298056156,\n",
       "   0.09071274298056156,\n",
       "   0.08855291576673865,\n",
       "   0.08855291576673865,\n",
       "   0.08423326133909287,\n",
       "   0.08423326133909287,\n",
       "   0.08207343412526998,\n",
       "   0.07991360691144708,\n",
       "   0.0755939524838013,\n",
       "   0.0734341252699784,\n",
       "   0.0734341252699784,\n",
       "   0.0734341252699784,\n",
       "   0.0734341252699784,\n",
       "   0.0734341252699784,\n",
       "   0.06911447084233262,\n",
       "   0.06695464362850972,\n",
       "   0.06263498920086392,\n",
       "   0.058315334773218146,\n",
       "   0.058315334773218146,\n",
       "   0.056155507559395246,\n",
       "   0.05399568034557235,\n",
       "   0.05183585313174946,\n",
       "   0.05183585313174946,\n",
       "   0.06695464362850972,\n",
       "   0.08423326133909287,\n",
       "   0.09503239740820735,\n",
       "   0.10583153347732181,\n",
       "   0.11663066954643629,\n",
       "   0.12958963282937366,\n",
       "   0.14254859611231102,\n",
       "   0.15766738660907129,\n",
       "   0.17278617710583152,\n",
       "   0.1879049676025918,\n",
       "   0.20518358531317496,\n",
       "   0.21814254859611232,\n",
       "   0.23110151187904968,\n",
       "   0.24406047516198703,\n",
       "   0.2570194384449244,\n",
       "   0.2678185745140389,\n",
       "   0.2786177105831533,\n",
       "   0.2937365010799136,\n",
       "   0.3045356371490281,\n",
       "   0.3174946004319654,\n",
       "   0.3282937365010799,\n",
       "   0.3390928725701944,\n",
       "   0.3412526997840173,\n",
       "   0.3434125269978402,\n",
       "   0.3434125269978402,\n",
       "   0.34557235421166305,\n",
       "   0.34557235421166305,\n",
       "   0.34773218142548595,\n",
       "   0.34773218142548595,\n",
       "   0.34773218142548595,\n",
       "   0.34773218142548595,\n",
       "   0.34773218142548595,\n",
       "   0.34773218142548595,\n",
       "   0.34773218142548595,\n",
       "   0.34773218142548595,\n",
       "   0.34557235421166305,\n",
       "   0.34557235421166305,\n",
       "   0.3434125269978402,\n",
       "   0.3412526997840173,\n",
       "   0.3412526997840173,\n",
       "   0.3390928725701944,\n",
       "   0.3347732181425486,\n",
       "   0.3326133909287257,\n",
       "   0.3304535637149028,\n",
       "   0.3304535637149028,\n",
       "   0.3282937365010799,\n",
       "   0.3282937365010799,\n",
       "   0.3282937365010799,\n",
       "   0.3282937365010799,\n",
       "   0.3282937365010799,\n",
       "   0.326133909287257,\n",
       "   0.32397408207343414,\n",
       "   0.32181425485961124,\n",
       "   0.31965442764578833,\n",
       "   0.3174946004319654,\n",
       "   0.31533477321814257,\n",
       "   0.31317494600431967,\n",
       "   0.31101511879049676,\n",
       "   0.31533477321814257,\n",
       "   0.32181425485961124,\n",
       "   0.326133909287257,\n",
       "   0.3326133909287257,\n",
       "   0.3434125269978402,\n",
       "   0.34989200863930886,\n",
       "   0.3563714902807775,\n",
       "   0.3650107991360691,\n",
       "   0.37365010799136067,\n",
       "   0.38876889848812096,\n",
       "   0.39956803455723544,\n",
       "   0.408207343412527,\n",
       "   0.4190064794816415,\n",
       "   0.42764578833693306,\n",
       "   0.43628509719222464,\n",
       "   0.4449244060475162,\n",
       "   0.44924406047516197,\n",
       "   0.45788336933045354,\n",
       "   0.46436285097192226,\n",
       "   0.4708423326133909,\n",
       "   0.47516198704103674,\n",
       "   0.4816414686825054,\n",
       "   0.4924406047516199,\n",
       "   0.49892008639308855,\n",
       "   0.5053995680345572,\n",
       "   0.5053995680345572],\n",
       "  [0.9719222462203023,\n",
       "   0.958963282937365,\n",
       "   0.9481641468682506,\n",
       "   0.9308855291576674,\n",
       "   0.9157667386609071,\n",
       "   0.9006479481641468,\n",
       "   0.8833693304535637,\n",
       "   0.8660907127429806,\n",
       "   0.8466522678185745,\n",
       "   0.8272138228941684,\n",
       "   0.8120950323974082,\n",
       "   0.7948164146868251,\n",
       "   0.7818574514038877,\n",
       "   0.7710583153347732,\n",
       "   0.7602591792656588,\n",
       "   0.7429805615550756,\n",
       "   0.7321814254859611,\n",
       "   0.7170626349892009,\n",
       "   0.7062634989200864,\n",
       "   0.6954643628509719,\n",
       "   0.6760259179265659,\n",
       "   0.6457883369330454,\n",
       "   0.6198704103671706,\n",
       "   0.5961123110151187,\n",
       "   0.5766738660907127,\n",
       "   0.5550755939524838,\n",
       "   0.5356371490280778,\n",
       "   0.5118790496760259,\n",
       "   0.48812095032397407,\n",
       "   0.46652267818574517,\n",
       "   0.4427645788336933,\n",
       "   0.42332613390928725,\n",
       "   0.4017278617710583,\n",
       "   0.3801295896328294,\n",
       "   0.3650107991360691,\n",
       "   0.34989200863930886,\n",
       "   0.3369330453563715,\n",
       "   0.32397408207343414,\n",
       "   0.31317494600431967,\n",
       "   0.2980561555075594,\n",
       "   0.28509719222462204,\n",
       "   0.26997840172786175,\n",
       "   0.2591792656587473,\n",
       "   0.24406047516198703,\n",
       "   0.23326133909287258,\n",
       "   0.21814254859611232,\n",
       "   0.20302375809935205,\n",
       "   0.1879049676025918,\n",
       "   0.17278617710583152,\n",
       "   0.15550755939524838,\n",
       "   0.13606911447084233,\n",
       "   0.11879049676025918,\n",
       "   0.10367170626349892,\n",
       "   0.08855291576673865,\n",
       "   0.0755939524838013,\n",
       "   0.06479481641468683,\n",
       "   0.05399568034557235,\n",
       "   0.04319654427645788,\n",
       "   0.032397408207343416,\n",
       "   0.02159827213822894,\n",
       "   0.01079913606911447,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0021598272138228943,\n",
       "   0.0064794816414686825,\n",
       "   0.008639308855291577,\n",
       "   0.012958963282937365,\n",
       "   0.012958963282937365,\n",
       "   0.01511879049676026,\n",
       "   0.017278617710583154,\n",
       "   0.019438444924406047,\n",
       "   0.02159827213822894,\n",
       "   0.023758099352051837,\n",
       "   0.023758099352051837,\n",
       "   0.02591792656587473,\n",
       "   0.028077753779697623,\n",
       "   0.028077753779697623,\n",
       "   0.03023758099352052,\n",
       "   0.032397408207343416,\n",
       "   0.03455723542116631,\n",
       "   0.03455723542116631,\n",
       "   0.0367170626349892,\n",
       "   0.038876889848812095,\n",
       "   0.04967602591792657,\n",
       "   0.06479481641468683,\n",
       "   0.07775377969762419,\n",
       "   0.08855291576673865,\n",
       "   0.11231101511879049,\n",
       "   0.13606911447084233,\n",
       "   0.16630669546436286,\n",
       "   0.1879049676025918,\n",
       "   0.21166306695464362,\n",
       "   0.23542116630669546,\n",
       "   0.2570194384449244,\n",
       "   0.28077753779697623,\n",
       "   0.3023758099352052,\n",
       "   0.32181425485961124,\n",
       "   0.3434125269978402,\n",
       "   0.36285097192224625,\n",
       "   0.38444924406047515,\n",
       "   0.4038876889848812,\n",
       "   0.42332613390928725,\n",
       "   0.4427645788336933,\n",
       "   0.46220302375809935,\n",
       "   0.4794816414686825,\n",
       "   0.49892008639308855,\n",
       "   0.5161987041036717,\n",
       "   0.531317494600432,\n",
       "   0.5464362850971922,\n",
       "   0.5637149028077754,\n",
       "   0.5809935205183585,\n",
       "   0.593952483801296,\n",
       "   0.6133909287257019,\n",
       "   0.6306695464362851,\n",
       "   0.6457883369330454,\n",
       "   0.6630669546436285,\n",
       "   0.673866090712743,\n",
       "   0.6846652267818575,\n",
       "   0.6954643628509719,\n",
       "   0.7062634989200864,\n",
       "   0.7213822894168467,\n",
       "   0.7321814254859611,\n",
       "   0.7429805615550756,\n",
       "   0.7580993520518359,\n",
       "   0.7688984881209503,\n",
       "   0.7796976241900648,\n",
       "   0.7904967602591793,\n",
       "   0.8012958963282938,\n",
       "   0.816414686825054,\n",
       "   0.8315334773218143,\n",
       "   0.8466522678185745,\n",
       "   0.8596112311015118,\n",
       "   0.8704103671706264,\n",
       "   0.8812095032397408,\n",
       "   0.896328293736501,\n",
       "   0.9071274298056156,\n",
       "   0.9200863930885529,\n",
       "   0.9330453563714903,\n",
       "   0.9438444924406048,\n",
       "   0.9546436285097192,\n",
       "   0.9676025917926566,\n",
       "   0.978401727861771,\n",
       "   0.9892008639308856,\n",
       "   1.0,\n",
       "   1.0],\n",
       "  [0,\n",
       "   39,\n",
       "   64,\n",
       "   97,\n",
       "   113,\n",
       "   131,\n",
       "   148,\n",
       "   165,\n",
       "   181,\n",
       "   197,\n",
       "   214,\n",
       "   231,\n",
       "   247,\n",
       "   265,\n",
       "   281,\n",
       "   314,\n",
       "   331,\n",
       "   364,\n",
       "   414,\n",
       "   682,\n",
       "   699,\n",
       "   715,\n",
       "   731,\n",
       "   747,\n",
       "   764,\n",
       "   780,\n",
       "   797,\n",
       "   813,\n",
       "   831,\n",
       "   846,\n",
       "   863,\n",
       "   880,\n",
       "   897,\n",
       "   914,\n",
       "   930,\n",
       "   947,\n",
       "   964,\n",
       "   981,\n",
       "   998,\n",
       "   1014,\n",
       "   1030,\n",
       "   1049,\n",
       "   1063,\n",
       "   1098,\n",
       "   1114,\n",
       "   1147,\n",
       "   1180,\n",
       "   1214,\n",
       "   1248,\n",
       "   1281,\n",
       "   1314,\n",
       "   1349,\n",
       "   1381,\n",
       "   1414,\n",
       "   1447,\n",
       "   1481,\n",
       "   1514,\n",
       "   1564,\n",
       "   1614,\n",
       "   1665,\n",
       "   1714,\n",
       "   1808,\n",
       "   1930,\n",
       "   1964,\n",
       "   1980,\n",
       "   1997,\n",
       "   2014,\n",
       "   2030,\n",
       "   2047,\n",
       "   2064,\n",
       "   2081,\n",
       "   2097,\n",
       "   2114,\n",
       "   2131,\n",
       "   2147,\n",
       "   2164,\n",
       "   2181,\n",
       "   2197,\n",
       "   2213,\n",
       "   2248,\n",
       "   2280,\n",
       "   2314,\n",
       "   2348,\n",
       "   2414,\n",
       "   2497,\n",
       "   2546,\n",
       "   2581,\n",
       "   2597,\n",
       "   2614,\n",
       "   2630,\n",
       "   2646,\n",
       "   2664,\n",
       "   2680,\n",
       "   2697,\n",
       "   2714,\n",
       "   2731,\n",
       "   2748,\n",
       "   2764,\n",
       "   2780,\n",
       "   2797,\n",
       "   2815,\n",
       "   2830,\n",
       "   2847,\n",
       "   2864,\n",
       "   2880,\n",
       "   2897,\n",
       "   2914,\n",
       "   2930,\n",
       "   2947,\n",
       "   2964,\n",
       "   2980,\n",
       "   2998,\n",
       "   3014,\n",
       "   3048,\n",
       "   3080,\n",
       "   3113,\n",
       "   3149,\n",
       "   3181,\n",
       "   3231,\n",
       "   3347,\n",
       "   3483,\n",
       "   3514,\n",
       "   3531,\n",
       "   3549,\n",
       "   3581,\n",
       "   3597,\n",
       "   3615,\n",
       "   3630,\n",
       "   3651,\n",
       "   3681,\n",
       "   3714,\n",
       "   3747,\n",
       "   3780,\n",
       "   3814,\n",
       "   3848,\n",
       "   3898,\n",
       "   3931,\n",
       "   3980,\n",
       "   4031,\n",
       "   4080,\n",
       "   4131,\n",
       "   4197,\n",
       "   4280,\n",
       "   4365,\n",
       "   4471,\n",
       "   4735]],\n",
       " [[0.07991360691144708,\n",
       "   0.07775377969762419,\n",
       "   0.09719222462203024,\n",
       "   0.1101511879049676,\n",
       "   0.12095032397408208,\n",
       "   0.13606911447084233,\n",
       "   0.1511879049676026,\n",
       "   0.16414686825053995,\n",
       "   0.17926565874730022,\n",
       "   0.19438444924406048,\n",
       "   0.20950323974082075,\n",
       "   0.22462203023758098,\n",
       "   0.23542116630669546,\n",
       "   0.24622030237580994,\n",
       "   0.2570194384449244,\n",
       "   0.2678185745140389,\n",
       "   0.28293736501079914,\n",
       "   0.2937365010799136,\n",
       "   0.3045356371490281,\n",
       "   0.3174946004319654,\n",
       "   0.3282937365010799,\n",
       "   0.3304535637149028],\n",
       "  [0.1079913606911447,\n",
       "   0.12311015118790497,\n",
       "   0.12526997840172785,\n",
       "   0.12742980561555076,\n",
       "   0.12742980561555076,\n",
       "   0.12742980561555076,\n",
       "   0.12742980561555076,\n",
       "   0.12742980561555076,\n",
       "   0.12742980561555076,\n",
       "   0.12742980561555076,\n",
       "   0.12742980561555076,\n",
       "   0.12742980561555076,\n",
       "   0.12526997840172785,\n",
       "   0.12526997840172785,\n",
       "   0.12526997840172785,\n",
       "   0.12526997840172785,\n",
       "   0.12742980561555076,\n",
       "   0.12958963282937366,\n",
       "   0.12958963282937366,\n",
       "   0.13174946004319654,\n",
       "   0.13390928725701945,\n",
       "   0.13822894168466524],\n",
       "  [6034,\n",
       "   6133,\n",
       "   6164,\n",
       "   6180,\n",
       "   6197,\n",
       "   6213,\n",
       "   6230,\n",
       "   6246,\n",
       "   6263,\n",
       "   6280,\n",
       "   6297,\n",
       "   6315,\n",
       "   6331,\n",
       "   6347,\n",
       "   6364,\n",
       "   6381,\n",
       "   6414,\n",
       "   6447,\n",
       "   6481,\n",
       "   6516,\n",
       "   6564,\n",
       "   6622]],\n",
       " [[0.09935205183585313,\n",
       "   0.1101511879049676,\n",
       "   0.12095032397408208,\n",
       "   0.13606911447084233,\n",
       "   0.15550755939524838,\n",
       "   0.17494600431965443,\n",
       "   0.19654427645788336,\n",
       "   0.2159827213822894,\n",
       "   0.23542116630669546,\n",
       "   0.2548596112311015,\n",
       "   0.2678185745140389,\n",
       "   0.2786177105831533,\n",
       "   0.2894168466522678,\n",
       "   0.3045356371490281,\n",
       "   0.31965442764578833,\n",
       "   0.3326133909287257,\n",
       "   0.3390928725701944],\n",
       "  [0.2634989200863931,\n",
       "   0.2634989200863931,\n",
       "   0.2634989200863931,\n",
       "   0.2634989200863931,\n",
       "   0.2634989200863931,\n",
       "   0.265658747300216,\n",
       "   0.26997840172786175,\n",
       "   0.27213822894168466,\n",
       "   0.27429805615550756,\n",
       "   0.27645788336933047,\n",
       "   0.27645788336933047,\n",
       "   0.27645788336933047,\n",
       "   0.2786177105831533,\n",
       "   0.2786177105831533,\n",
       "   0.28077753779697623,\n",
       "   0.28293736501079914,\n",
       "   0.28509719222462204],\n",
       "  [7227,\n",
       "   7298,\n",
       "   7314,\n",
       "   7330,\n",
       "   7347,\n",
       "   7363,\n",
       "   7380,\n",
       "   7397,\n",
       "   7414,\n",
       "   7430,\n",
       "   7447,\n",
       "   7463,\n",
       "   7480,\n",
       "   7513,\n",
       "   7547,\n",
       "   7597,\n",
       "   7689]]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drawing_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the input format and shape:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to formalize the input shape to be used in `encode_stroke` signature\n",
    "# Specifically, the shape of `input_seq_len` is (None, ) and the shape of input_stroke is (None, None, 3) \n",
    "def formalize_input(stroke):\n",
    "    input_stroke_tensor = tf.convert_to_tensor([stroke], dtype=tf.float32) # Add an extra dimension for batch size\n",
    "    input_seq_len_tensor = tf.convert_to_tensor([len(stroke)], dtype=tf.int32)\n",
    "\n",
    "    return input_seq_len_tensor, input_stroke_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use pretrained model for prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try the encode_stroke signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ConcreteFunction (*, input_seq_len: TensorSpec(shape=(None,), dtype=tf.int32, name='input_seq_len'), input_stroke: TensorSpec(shape=(None, None, 3), dtype=tf.float32, name='input_stroke')) -> Dict[['embedding_sample', TensorSpec(shape=(None, 8), dtype=tf.float32, name='embedding_sample')]] at 0x341229B90>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode_stroke = model.signatures[\"encode_stroke\"]\n",
    "encode_stroke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists to collect embeddings and positions\n",
    "embedding_sample_list = []\n",
    "inp_pos_list = []\n",
    "\n",
    "# Process only the first two strokes\n",
    "for stroke in drawing_resampled[:2]:\n",
    "    input_seq_len_tensor, input_stroke_tensor = formalize_input(stroke)\n",
    "    output = encode_stroke(input_seq_len=input_seq_len_tensor, \n",
    "                           input_stroke=input_stroke_tensor)\n",
    "    embedding_sample = output[\"embedding_sample\"]\n",
    "    \n",
    "    # Extract the first point's coordinates as position\n",
    "    inp_pos = [[stroke[0][0], stroke[1][0]]]\n",
    "    inp_pos_list.extend(inp_pos)\n",
    "    embedding_sample_list.append(embedding_sample)\n",
    "\n",
    "# Convert lists to tensors with the right shape\n",
    "inp_pos_tensor = tf.convert_to_tensor(inp_pos_list, dtype=tf.float32)  # Shape: (num_strokes, 2)\n",
    "inp_embeddings_tensor = tf.concat(embedding_sample_list, axis=0)  # Shape: (num_strokes, 8)\n",
    "\n",
    "# Add batch dimension\n",
    "inp_pos_tensor = tf.expand_dims(inp_pos_tensor, axis=0)  # Shape: (1, num_strokes, 2)\n",
    "inp_embeddings_tensor = tf.expand_dims(inp_embeddings_tensor, axis=0)  # Shape: (1, num_strokes, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try the predict_position signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ConcreteFunction (*, inp_pos: TensorSpec(shape=(None, None, 2), dtype=tf.float32, name='inp_pos'), inp_embeddings: TensorSpec(shape=(None, None, 8), dtype=tf.float32, name='inp_embeddings')) -> Dict[['position_sample', TensorSpec(shape=(None, 2), dtype=tf.float32, name='position_sample')], ['pi', TensorSpec(shape=(None, 10), dtype=tf.float32, name='pi')], ['sigma', TensorSpec(shape=(None, 1, 10, 2), dtype=tf.float32, name='sigma')], ['mu', TensorSpec(shape=(None, 1, 10, 2), dtype=tf.float32, name='mu')]] at 0x34C8FFA90>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_position = model.signatures[\"predict_position\"]\n",
    "predict_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'position_sample': <tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[ 5.0079856, -1.7939286]], dtype=float32)>,\n",
       " 'pi': <tf.Tensor: shape=(1, 10), dtype=float32, numpy=\n",
       " array([[4.9947449e-08, 4.1465189e-08, 3.4878403e-07, 2.9787504e-09,\n",
       "         9.9642249e-04, 1.7822293e-06, 5.7293884e-02, 3.3884905e-07,\n",
       "         9.4170719e-01, 3.4080483e-09]], dtype=float32)>,\n",
       " 'sigma': <tf.Tensor: shape=(1, 1, 10, 2), dtype=float32, numpy=\n",
       " array([[[[ 9.469406  ,  3.93775   ],\n",
       "          [ 1.8703833 ,  4.1385603 ],\n",
       "          [ 6.523202  ,  0.9962487 ],\n",
       "          [35.05433   ,  3.7892816 ],\n",
       "          [ 0.16137658,  0.64853305],\n",
       "          [ 1.0840179 ,  0.38157785],\n",
       "          [22.735527  ,  1.0849528 ],\n",
       "          [35.106552  ,  2.1862864 ],\n",
       "          [18.42456   ,  5.7575884 ],\n",
       "          [ 4.4909253 ,  0.9814574 ]]]], dtype=float32)>,\n",
       " 'mu': <tf.Tensor: shape=(1, 1, 10, 2), dtype=float32, numpy=\n",
       " array([[[[-0.78398544,  1.8392066 ],\n",
       "          [ 0.09649509,  1.2448666 ],\n",
       "          [-0.2920542 , -0.02970675],\n",
       "          [-2.3142333 , -0.03924352],\n",
       "          [ 2.6677096 , -0.34294257],\n",
       "          [ 0.0727037 , -0.10952401],\n",
       "          [ 3.305124  , -1.3384072 ],\n",
       "          [-0.20732039, -2.6159925 ],\n",
       "          [ 5.0079856 , -1.7939286 ],\n",
       "          [-1.8515248 ,  0.6015358 ]]]], dtype=float32)>}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_position_result = predict_position(inp_pos=inp_pos_tensor, \n",
    "                                           inp_embeddings=inp_embeddings_tensor)\n",
    "predict_position_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_pos = predict_position_result['position_sample']\n",
    "target_pos_tensor = tf.expand_dims(target_pos, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try predict_embedding signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ConcreteFunction (*, inp_pos: TensorSpec(shape=(None, None, 2), dtype=tf.float32, name='inp_pos'), target_pos: TensorSpec(shape=(None, 1, 2), dtype=tf.float32, name='target_pos'), inp_embeddings: TensorSpec(shape=(None, None, 8), dtype=tf.float32, name='inp_embeddings')) -> Dict[['pi', TensorSpec(shape=(None, 10), dtype=tf.float32, name='pi')], ['sigma', TensorSpec(shape=(None, 1, 10, 8), dtype=tf.float32, name='sigma')], ['embedding_sample', TensorSpec(shape=(None, 8), dtype=tf.float32, name='embedding_sample')], ['mu', TensorSpec(shape=(None, 1, 10, 8), dtype=tf.float32, name='mu')]] at 0x367F4BB10>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_embedding = model.signatures[\"predict_embedding\"]\n",
    "predict_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pi': <tf.Tensor: shape=(1, 10), dtype=float32, numpy=\n",
       " array([[0.09046026, 0.11755432, 0.14144145, 0.11475937, 0.11965625,\n",
       "         0.04789938, 0.06722607, 0.14215028, 0.02967727, 0.12917535]],\n",
       "       dtype=float32)>,\n",
       " 'sigma': <tf.Tensor: shape=(1, 1, 10, 8), dtype=float32, numpy=\n",
       " array([[[[0.45284918, 0.29740077, 0.15811475, 0.41532522, 0.23129684,\n",
       "           0.2014866 , 0.5296572 , 0.2501981 ],\n",
       "          [0.4723905 , 0.26922047, 0.3173757 , 0.29430878, 0.2629834 ,\n",
       "           0.36324573, 0.46068507, 0.30033436],\n",
       "          [0.3568875 , 0.42014602, 0.29737753, 0.45211092, 0.42484426,\n",
       "           0.3818772 , 0.46291026, 0.2178421 ],\n",
       "          [0.3622169 , 0.31614846, 0.206989  , 0.4615963 , 0.2814282 ,\n",
       "           0.20501602, 0.53985107, 0.3541556 ],\n",
       "          [0.273858  , 0.21198273, 0.22635981, 0.40452194, 0.21225491,\n",
       "           0.48606813, 0.19932765, 0.23868212],\n",
       "          [0.3943012 , 0.47304624, 0.26862285, 0.47427455, 0.60211563,\n",
       "           0.5168385 , 0.50502825, 0.34702405],\n",
       "          [0.30112642, 0.28722677, 0.2987135 , 0.48334852, 0.2866118 ,\n",
       "           0.27348912, 0.3967425 , 0.31689185],\n",
       "          [0.30987158, 0.14708327, 0.23801339, 0.3329318 , 0.15571085,\n",
       "           0.21191043, 0.2035982 , 0.23237891],\n",
       "          [0.4335206 , 0.27628022, 0.32084653, 0.499611  , 0.28662306,\n",
       "           0.30892092, 0.363936  , 0.34367642],\n",
       "          [0.3013934 , 0.41506758, 0.24529637, 0.34649193, 0.31687817,\n",
       "           0.28988478, 0.42230412, 0.3128063 ]]]], dtype=float32)>,\n",
       " 'embedding_sample': <tf.Tensor: shape=(1, 8), dtype=float32, numpy=\n",
       " array([[ 1.3232666 ,  0.21300374, -0.0584728 , -1.3286681 , -0.18778224,\n",
       "          0.21400708,  0.407911  , -0.29385394]], dtype=float32)>,\n",
       " 'mu': <tf.Tensor: shape=(1, 1, 10, 8), dtype=float32, numpy=\n",
       " array([[[[ 0.6002583 ,  0.64875764,  0.5107041 , -1.1787232 ,\n",
       "           -0.13511956,  0.02765517,  1.3224401 , -0.3857222 ],\n",
       "          [ 1.430979  ,  0.3844045 ,  0.39434063, -0.59683275,\n",
       "            0.05579299, -0.34556395,  0.5679105 , -0.1932686 ],\n",
       "          [ 0.1567817 ,  0.11424187,  0.38380057, -1.7696438 ,\n",
       "           -0.14112258,  0.44051653,  0.31136894, -0.47317567],\n",
       "          [ 0.80144787, -0.04703337,  0.19679372, -0.6222779 ,\n",
       "            0.13340342, -0.205149  ,  0.37757513, -0.02524494],\n",
       "          [ 0.7148527 , -0.00504168, -0.091415  , -1.9343919 ,\n",
       "            0.18050745, -0.25859526,  0.3518322 , -0.06685957],\n",
       "          [ 0.27491796, -0.11828785,  0.14466879, -1.4270186 ,\n",
       "            0.58885175,  0.09597553,  1.1455381 , -0.10378842],\n",
       "          [-0.04508518,  0.1453104 ,  0.4045161 , -1.6563884 ,\n",
       "           -0.31629622,  0.50878096,  0.46443388, -0.23068152],\n",
       "          [ 1.3232666 ,  0.21300374, -0.0584728 , -1.3286681 ,\n",
       "           -0.18778224,  0.21400708,  0.407911  , -0.29385394],\n",
       "          [ 0.76682204,  0.11500756,  0.23286885, -1.828588  ,\n",
       "           -0.64394605,  0.45314732, -0.09667996, -0.18327746],\n",
       "          [ 1.314671  ,  0.00496066,  0.2671154 , -0.51556027,\n",
       "            0.79963607, -0.36652195,  1.0904391 , -0.08658283]]]],\n",
       "       dtype=float32)>}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_embedding_result = predict_embedding(inp_pos=inp_pos_tensor, \n",
    "                                             target_pos=target_pos_tensor,\n",
    "                                             inp_embeddings=inp_embeddings_tensor)\n",
    "predict_embedding_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try the decode_stroke signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ConcreteFunction (*, embedding_sample: TensorSpec(shape=(None, 8), dtype=tf.float32, name='embedding_sample'), target_seq_len: TensorSpec(shape=(), dtype=tf.int32, name='target_seq_len')) -> Dict[['pen', TensorSpec(shape=(None, None, 1), dtype=tf.float32, name='pen')], ['seq_len', TensorSpec(shape=(None,), dtype=tf.int32, name='seq_len')], ['stroke', TensorSpec(shape=(None, None, 2), dtype=tf.float32, name='stroke')]] at 0x34B261CD0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_stroke = model.signatures[\"decode_stroke\"]\n",
    "decode_stroke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 17, 2), dtype=float32, numpy=\n",
       "array([[[ -0.32955068,  -0.22248104],\n",
       "        [ -0.6766161 ,  -0.49407703],\n",
       "        [ -2.0241368 ,  -5.802304  ],\n",
       "        [ -5.119701  , -15.102497  ],\n",
       "        [ -5.5239687 , -18.375616  ],\n",
       "        [ -2.6613305 , -17.858814  ],\n",
       "        [  0.9564642 , -16.767225  ],\n",
       "        [  3.9374683 , -15.174292  ],\n",
       "        [  5.4061937 , -11.872535  ],\n",
       "        [  6.628682  ,  -5.2172203 ],\n",
       "        [  4.7367835 ,   3.5651972 ],\n",
       "        [  4.209163  ,   2.217497  ],\n",
       "        [  1.1554601 ,   4.8128157 ],\n",
       "        [ -0.8442453 ,   3.380175  ],\n",
       "        [ -2.2247639 ,   2.0960534 ],\n",
       "        [ -2.9414732 ,  -0.9859777 ],\n",
       "        [ -2.8693335 ,  -1.7561842 ]]], dtype=float32)>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the (real) next stroke to determine the target_seq_len for the decoder\n",
    "target_seq_len_tensor = tf.convert_to_tensor(len(drawing_resampled[2]), dtype=tf.int32)\n",
    "\n",
    "decode_stroke_result = decode_stroke(embedding_sample = predict_embedding_result[\"embedding_sample\"],\n",
    "                                     target_seq_len = target_seq_len_tensor)\n",
    "\n",
    "decode_stroke_result[\"stroke\"]\n",
    "# This decoded stroke with pen state and stroke are used as the new input \n",
    "# for the encoder, whose starting position and embeddings will be used\n",
    "# for auto-regressive for the remaining stokes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Try Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def process_drawing_for_encode_stroke(drawing):\n",
    "#     flat_strokes = []\n",
    "#     total_points = 0\n",
    "#     for stroke in drawing:\n",
    "#         for i in range(len(stroke[0])):  # Iterate through points in the stroke\n",
    "#             x = stroke[0][i]\n",
    "#             y = stroke[1][i]\n",
    "#             # Assuming the third list contains timing information, not directly used here\n",
    "#             # If there's a specific \"pen state\" value needed, adjust accordingly\n",
    "#             flat_strokes.append([x, y, 1])  # Use '1' as a placeholder for pen state\n",
    "#         total_points += len(stroke[0])\n",
    "    \n",
    "#     # Convert to tensors\n",
    "#     input_stroke = tf.constant(flat_strokes, dtype=tf.float32)\n",
    "#     input_seq_len = tf.constant([total_points], dtype=tf.int32)\n",
    "    \n",
    "#     return input_stroke, input_seq_len\n",
    "\n",
    "# # Find the maximum sequence length across all processed drawings\n",
    "# max_seq_len = max(input_stroke.shape[0] for input_stroke, _ in processed_drawings)\n",
    "\n",
    "# # Pad each drawing sequence to the maximum length\n",
    "# padded_drawings = []\n",
    "# for input_stroke, input_seq_len in processed_drawings:\n",
    "#     # Calculate the padding amounts\n",
    "#     padding = [[0, max_seq_len - tf.shape(input_stroke)[0]], [0, 0]]  # Pad the sequence length to max_seq_len\n",
    "    \n",
    "#     # Pad the stroke data\n",
    "#     padded_stroke = tf.pad(input_stroke, padding, \"CONSTANT\")\n",
    "    \n",
    "#     # Append the padded stroke and original sequence length\n",
    "#     padded_drawings.append((padded_stroke, input_seq_len))\n",
    "\n",
    "# padded_drawings\n",
    "\n",
    "# import json\n",
    "\n",
    "# processed_drawings = []\n",
    "\n",
    "# # Draw a sample of 320 sketches\n",
    "# max_rows = 320\n",
    "# current_row = 0\n",
    "\n",
    "# with open(\"data_dir/quick_draw/raw_Eiffel_Tower.ndjson\", 'r') as f:\n",
    "#     for line in f:\n",
    "#         if current_row < max_rows:\n",
    "#             drawing_data = json.loads(line)\n",
    "#             drawing = drawing_data[\"drawing\"]\n",
    "#             processed_drawing = process_drawing_for_encode_stroke(drawing)\n",
    "#             processed_drawings.append(processed_drawing)\n",
    "#             current_row += 1\n",
    "#         else:\n",
    "#             break\n",
    "# stroke_tensors = [x[0] for x in padded_drawings]\n",
    "# seq_len_tensors = [x[1] for x in padded_drawings]\n",
    "\n",
    "# stroke_dataset = tf.data.Dataset.from_tensor_slices(stroke_tensors)\n",
    "# seq_len_dataset = tf.data.Dataset.from_tensor_slices(seq_len_tensors)\n",
    "\n",
    "# # Combine into a single dataset\n",
    "# dataset = tf.data.Dataset.zip((stroke_dataset, seq_len_dataset))\n",
    "\n",
    "# dataset\n",
    "\n",
    "# # Set your desired batch size\n",
    "# batch_size = 128\n",
    "\n",
    "# # Batch the dataset. No need to specify padding values or shapes here because\n",
    "# # your tensors within each dataset element already have a uniform shape after padding.\n",
    "# batched_dataset = dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the features of importance for input formatting\n",
    "# feature_description = {\n",
    "#     'ink': tf.io.VarLenFeature(tf.float32),\n",
    "# }\n",
    "\n",
    "# # For now, I use a very small sample of dataset\n",
    "# file_paths = \"data_dir/quick_draw/training/raw_Eiffel_Tower-00000-of-00010\"\n",
    "# dataset = tf.data.TFRecordDataset(file_paths)\n",
    "\n",
    "# # for raw_record in dataset.take(1):\n",
    "# #   example = tf.train.Example()\n",
    "# #   example.ParseFromString(raw_record.numpy())\n",
    "# #   print(example)\n",
    "\n",
    "# # Parse a Tensorflow Example proto \n",
    "# parsed_dataset = dataset.map(lambda x: tf.io.parse_single_example(x, feature_description)) \n",
    "\n",
    "# # Define a function to get the `input_seq_len` and `input_stroke` arguments \n",
    "# # for fitting the pretrained model (specifically, `encode_stroke` signature)\n",
    "# max_length_threshold = 201\n",
    "\n",
    "# def get_input_arguments(parsed_record):\n",
    "#     # Reshape and extract the first three dimensions from parsed_record['ink']\n",
    "#     # (x coordinate, y coordinate, and pen state)\n",
    "#     ink = tf.sparse.to_dense(parsed_record['ink'])\n",
    "#     input_seq_len = tf.shape(ink)[0] // 4\n",
    "#     ink_reshaped = tf.reshape(ink, (input_seq_len, 4))\n",
    "#     # Expand the input_stroke to three dimensions for batching \n",
    "#     input_stroke = tf.expand_dims(ink_reshaped[:, :3], axis=0)\n",
    "    \n",
    "#     # Make sure it matches the input shape \n",
    "#     input_seq_len = tf.reshape(input_seq_len, [1]) \n",
    "\n",
    "#     return input_seq_len, input_stroke\n",
    "    \n",
    "# preprocessed_dataset = parsed_dataset.map(get_input_arguments)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

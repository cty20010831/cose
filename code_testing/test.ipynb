{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import linecache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.saved_model.load(\"../pretrained_model/saved_model_with_signatures\")\n",
    "\n",
    "model_signature_directory = '../pretrained_model/model_architecture.csv'\n",
    "\n",
    "if os.path.exists(model_signature_directory):\n",
    "    # Collecting signature details\n",
    "    signatures_data = []\n",
    "\n",
    "    # Iterate over each signature in the model\n",
    "    for key, signature in model.signatures.items():\n",
    "        # Initialize dictionaries for current signature's inputs and outputs\n",
    "        inputs_dict = {}\n",
    "        outputs_dict = {}\n",
    "\n",
    "        # Iterate over inputs and outputs, filling in the dictionaries\n",
    "        for input_key, input_val in signature.structured_input_signature[1].items():\n",
    "            inputs_dict[input_key] = str(input_val.dtype.name)\n",
    "\n",
    "        for output_key, output_val in signature.structured_outputs.items():\n",
    "            outputs_dict[output_key] = str(output_val.dtype.name)\n",
    "\n",
    "        # Append the current signature's details to the list\n",
    "        signatures_data.append({\n",
    "            \"Signature Key\": key,\n",
    "            \"Inputs\": inputs_dict,\n",
    "            \"Outputs\": outputs_dict\n",
    "        })\n",
    "\n",
    "    # Convert list of signature data into a DataFrame for visualization\n",
    "    df_signatures = pd.DataFrame(signatures_data)\n",
    "\n",
    "    df_inputs = df_signatures[\"Inputs\"].apply(pd.Series)\n",
    "    df_outputs = df_signatures[\"Outputs\"].apply(pd.Series)\n",
    "    df_expanded = pd.concat([df_signatures.drop(['Inputs', 'Outputs'], axis=1), df_inputs, df_outputs], axis=1)\n",
    "    df_expanded.to_csv(\"../pretrained_model/model_architecture.csv\", index=False)\n",
    "else:\n",
    "    df_expanded = pd.read_csv(model_signature_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Signature Key</th>\n",
       "      <th>embedding_sample</th>\n",
       "      <th>target_seq_len</th>\n",
       "      <th>inp_pos</th>\n",
       "      <th>target_pos</th>\n",
       "      <th>inp_embeddings</th>\n",
       "      <th>input_seq_len</th>\n",
       "      <th>input_stroke</th>\n",
       "      <th>pen</th>\n",
       "      <th>seq_len</th>\n",
       "      <th>stroke</th>\n",
       "      <th>pi</th>\n",
       "      <th>sigma</th>\n",
       "      <th>embedding_sample</th>\n",
       "      <th>mu</th>\n",
       "      <th>position_sample</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>decode_stroke</td>\n",
       "      <td>float32</td>\n",
       "      <td>int32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>float32</td>\n",
       "      <td>int32</td>\n",
       "      <td>float32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>predict_embedding</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>float32</td>\n",
       "      <td>float32</td>\n",
       "      <td>float32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>float32</td>\n",
       "      <td>float32</td>\n",
       "      <td>float32</td>\n",
       "      <td>float32</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>predict_position</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>float32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>float32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>float32</td>\n",
       "      <td>float32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>float32</td>\n",
       "      <td>float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>encode_stroke</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>int32</td>\n",
       "      <td>float32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>float32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>forward_pass</td>\n",
       "      <td>NaN</td>\n",
       "      <td>int32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>int32</td>\n",
       "      <td>float32</td>\n",
       "      <td>float32</td>\n",
       "      <td>int32</td>\n",
       "      <td>float32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>float32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Signature Key embedding_sample target_seq_len  inp_pos target_pos  \\\n",
       "0      decode_stroke          float32          int32      NaN        NaN   \n",
       "1  predict_embedding              NaN            NaN  float32    float32   \n",
       "2   predict_position              NaN            NaN  float32        NaN   \n",
       "3      encode_stroke              NaN            NaN      NaN        NaN   \n",
       "4       forward_pass              NaN          int32      NaN        NaN   \n",
       "\n",
       "  inp_embeddings input_seq_len input_stroke      pen seq_len   stroke  \\\n",
       "0            NaN           NaN          NaN  float32   int32  float32   \n",
       "1        float32           NaN          NaN      NaN     NaN      NaN   \n",
       "2        float32           NaN          NaN      NaN     NaN      NaN   \n",
       "3            NaN         int32      float32      NaN     NaN      NaN   \n",
       "4            NaN         int32      float32  float32   int32  float32   \n",
       "\n",
       "        pi    sigma embedding_sample       mu position_sample  \n",
       "0      NaN      NaN              NaN      NaN             NaN  \n",
       "1  float32  float32          float32  float32             NaN  \n",
       "2  float32  float32              NaN  float32         float32  \n",
       "3      NaN      NaN          float32      NaN             NaN  \n",
       "4      NaN      NaN          float32      NaN             NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_expanded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocesses raw drawings and get the right input format for `encode_stroke`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions to adjusts all drawings to have a consistent scale or size\n",
    "def get_bounding_box(drawing):\n",
    "    minx = 99999\n",
    "    miny = 99999\n",
    "    maxx = 0\n",
    "    maxy = 0\n",
    "\n",
    "    for s in drawing:\n",
    "      minx = min(minx, min(s[0]))\n",
    "      maxx = max(maxx, max(s[0]))\n",
    "      miny = min(miny, min(s[1]))\n",
    "      maxy = max(maxy, max(s[1]))\n",
    "    return (minx, miny, maxx, maxy)\n",
    "\n",
    "def size_normalization(drawing):\n",
    "  bb = get_bounding_box(drawing)\n",
    "  width, height = bb[2] - bb[0], bb[3] - bb[1]\n",
    "  offset_x, offset_y = bb[0], bb[1]\n",
    "  if height < 1e-6:\n",
    "    height = 1\n",
    "\n",
    "  size_normalized_drawing = [[[(x - offset_x) / height for x in stroke[0]],\n",
    "                              [(y - offset_y) / height for y in stroke[1]],\n",
    "                              [t for t in stroke[2]]]\n",
    "                             for stroke in drawing]\n",
    "\n",
    "  return size_normalized_drawing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to resample the ink to have uniform time steps\n",
    "# (Ensure that each point is separated by a constant time step)\n",
    "def resample_ink(drawing, timestep=20):\n",
    "    resampled_drawing = []\n",
    "    \n",
    "    for stroke in drawing:\n",
    "        # Initialize with the first point\n",
    "        resampled_stroke = [[stroke[0][0], stroke[1][0], stroke[2][0]]]  \n",
    "        \n",
    "        for i in range(1, len(stroke[0])):\n",
    "            x0, y0, t0 = stroke[0][i-1], stroke[1][i-1], stroke[2][i-1]\n",
    "            x1, y1, t1 = stroke[0][i], stroke[1][i], stroke[2][i]\n",
    "            distance = np.sqrt((x1 - x0)**2 + (y1 - y0)**2)\n",
    "            if distance == 0:\n",
    "                continue\n",
    "            else:\n",
    "                new_points = max(1, int(distance / timestep))\n",
    "                for j in range(1, new_points + 1):\n",
    "                    new_point = [x0 + j * (x1 - x0) / new_points,\n",
    "                                y0 + j * (y1 - y0) / new_points,\n",
    "                                t0 + j * (t1 - t0) / new_points]\n",
    "                    resampled_stroke.append(new_point)\n",
    "        \n",
    "        resampled_drawing.append(resampled_stroke)\n",
    "\n",
    "    return resampled_drawing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I try with the first drawing in quick_draw_Eiffel_Tower:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are totally 3 strokes in the sample drawing\n"
     ]
    }
   ],
   "source": [
    "ndjson_file_path = 'full_raw_The_Eiffel_Tower.ndjson'\n",
    "\n",
    "# Select the line to read as the sample drawing\n",
    "line_number = 12\n",
    "# Use linecache to get the specific line\n",
    "line = linecache.getline(ndjson_file_path, line_number).strip()\n",
    "# Parse the JSON content from the line\n",
    "selected_row = json.loads(line)\n",
    "\n",
    "sample_drawing = selected_row[\"drawing\"]\n",
    "print(f\"There are totally {len(sample_drawing)} strokes in the sample drawing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[146, 22, 17]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sequence length for each stroke\n",
    "[len(i[0]) for i in sample_drawing]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the drawing\n",
    "drawing_normalized = size_normalization(sample_drawing)\n",
    "drawing_resampled = resample_ink(drawing_normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the input format and shape:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to formalize the input shape to be used in `encode_stroke` signature\n",
    "# Specifically, the shape of `input_seq_len` is (None, ) and the shape of input_stroke is (None, None, 3) \n",
    "def formalize_input(stroke):\n",
    "    input_stroke_tensor = tf.convert_to_tensor([stroke], dtype=tf.float32) # Add an extra dimension for batch size\n",
    "    input_seq_len_tensor = tf.convert_to_tensor([len(stroke)], dtype=tf.int32)\n",
    "\n",
    "    return input_seq_len_tensor, input_stroke_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use pretrained model for prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try the encode_stroke signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ConcreteFunction (*, input_seq_len: TensorSpec(shape=(None,), dtype=tf.int32, name='input_seq_len'), input_stroke: TensorSpec(shape=(None, None, 3), dtype=tf.float32, name='input_stroke')) -> Dict[['embedding_sample', TensorSpec(shape=(None, 8), dtype=tf.float32, name='embedding_sample')]] at 0x341229B90>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode_stroke = model.signatures[\"encode_stroke\"]\n",
    "encode_stroke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists to collect embeddings and positions\n",
    "embedding_sample_list = []\n",
    "inp_pos_list = []\n",
    "\n",
    "# Process only the first two strokes\n",
    "for stroke in drawing_resampled[:2]:\n",
    "    input_seq_len_tensor, input_stroke_tensor = formalize_input(stroke)\n",
    "    output = encode_stroke(input_seq_len=input_seq_len_tensor, \n",
    "                           input_stroke=input_stroke_tensor)\n",
    "    embedding_sample = output[\"embedding_sample\"]\n",
    "    \n",
    "    # Extract the first point's coordinates as position\n",
    "    inp_pos = [[stroke[0][0], stroke[1][0]]]\n",
    "    inp_pos_list.extend(inp_pos)\n",
    "    embedding_sample_list.append(embedding_sample)\n",
    "\n",
    "# Convert lists to tensors with the right shape\n",
    "inp_pos_tensor = tf.convert_to_tensor(inp_pos_list, dtype=tf.float32)  # Shape: (num_strokes, 2)\n",
    "inp_embeddings_tensor = tf.concat(embedding_sample_list, axis=0)  # Shape: (num_strokes, 8)\n",
    "\n",
    "# Add batch dimension\n",
    "inp_pos_tensor = tf.expand_dims(inp_pos_tensor, axis=0)  # Shape: (1, num_strokes, 2)\n",
    "inp_embeddings_tensor = tf.expand_dims(inp_embeddings_tensor, axis=0)  # Shape: (1, num_strokes, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try the predict_position signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ConcreteFunction (*, inp_pos: TensorSpec(shape=(None, None, 2), dtype=tf.float32, name='inp_pos'), inp_embeddings: TensorSpec(shape=(None, None, 8), dtype=tf.float32, name='inp_embeddings')) -> Dict[['position_sample', TensorSpec(shape=(None, 2), dtype=tf.float32, name='position_sample')], ['pi', TensorSpec(shape=(None, 10), dtype=tf.float32, name='pi')], ['sigma', TensorSpec(shape=(None, 1, 10, 2), dtype=tf.float32, name='sigma')], ['mu', TensorSpec(shape=(None, 1, 10, 2), dtype=tf.float32, name='mu')]] at 0x34C8FFA90>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_position = model.signatures[\"predict_position\"]\n",
    "predict_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'position_sample': <tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[ 5.0079856, -1.7939286]], dtype=float32)>,\n",
       " 'pi': <tf.Tensor: shape=(1, 10), dtype=float32, numpy=\n",
       " array([[4.9947449e-08, 4.1465189e-08, 3.4878403e-07, 2.9787504e-09,\n",
       "         9.9642249e-04, 1.7822293e-06, 5.7293884e-02, 3.3884905e-07,\n",
       "         9.4170719e-01, 3.4080483e-09]], dtype=float32)>,\n",
       " 'sigma': <tf.Tensor: shape=(1, 1, 10, 2), dtype=float32, numpy=\n",
       " array([[[[ 9.469406  ,  3.93775   ],\n",
       "          [ 1.8703833 ,  4.1385603 ],\n",
       "          [ 6.523202  ,  0.9962487 ],\n",
       "          [35.05433   ,  3.7892816 ],\n",
       "          [ 0.16137658,  0.64853305],\n",
       "          [ 1.0840179 ,  0.38157785],\n",
       "          [22.735527  ,  1.0849528 ],\n",
       "          [35.106552  ,  2.1862864 ],\n",
       "          [18.42456   ,  5.7575884 ],\n",
       "          [ 4.4909253 ,  0.9814574 ]]]], dtype=float32)>,\n",
       " 'mu': <tf.Tensor: shape=(1, 1, 10, 2), dtype=float32, numpy=\n",
       " array([[[[-0.78398544,  1.8392066 ],\n",
       "          [ 0.09649509,  1.2448666 ],\n",
       "          [-0.2920542 , -0.02970675],\n",
       "          [-2.3142333 , -0.03924352],\n",
       "          [ 2.6677096 , -0.34294257],\n",
       "          [ 0.0727037 , -0.10952401],\n",
       "          [ 3.305124  , -1.3384072 ],\n",
       "          [-0.20732039, -2.6159925 ],\n",
       "          [ 5.0079856 , -1.7939286 ],\n",
       "          [-1.8515248 ,  0.6015358 ]]]], dtype=float32)>}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_position_result = predict_position(inp_pos=inp_pos_tensor, \n",
    "                                           inp_embeddings=inp_embeddings_tensor)\n",
    "predict_position_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_pos = predict_position_result['position_sample']\n",
    "target_pos_tensor = tf.expand_dims(target_pos, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try predict_embedding signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ConcreteFunction (*, inp_pos: TensorSpec(shape=(None, None, 2), dtype=tf.float32, name='inp_pos'), target_pos: TensorSpec(shape=(None, 1, 2), dtype=tf.float32, name='target_pos'), inp_embeddings: TensorSpec(shape=(None, None, 8), dtype=tf.float32, name='inp_embeddings')) -> Dict[['pi', TensorSpec(shape=(None, 10), dtype=tf.float32, name='pi')], ['sigma', TensorSpec(shape=(None, 1, 10, 8), dtype=tf.float32, name='sigma')], ['embedding_sample', TensorSpec(shape=(None, 8), dtype=tf.float32, name='embedding_sample')], ['mu', TensorSpec(shape=(None, 1, 10, 8), dtype=tf.float32, name='mu')]] at 0x367F4BB10>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_embedding = model.signatures[\"predict_embedding\"]\n",
    "predict_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pi': <tf.Tensor: shape=(1, 10), dtype=float32, numpy=\n",
       " array([[0.09046026, 0.11755432, 0.14144145, 0.11475937, 0.11965625,\n",
       "         0.04789938, 0.06722607, 0.14215028, 0.02967727, 0.12917535]],\n",
       "       dtype=float32)>,\n",
       " 'sigma': <tf.Tensor: shape=(1, 1, 10, 8), dtype=float32, numpy=\n",
       " array([[[[0.45284918, 0.29740077, 0.15811475, 0.41532522, 0.23129684,\n",
       "           0.2014866 , 0.5296572 , 0.2501981 ],\n",
       "          [0.4723905 , 0.26922047, 0.3173757 , 0.29430878, 0.2629834 ,\n",
       "           0.36324573, 0.46068507, 0.30033436],\n",
       "          [0.3568875 , 0.42014602, 0.29737753, 0.45211092, 0.42484426,\n",
       "           0.3818772 , 0.46291026, 0.2178421 ],\n",
       "          [0.3622169 , 0.31614846, 0.206989  , 0.4615963 , 0.2814282 ,\n",
       "           0.20501602, 0.53985107, 0.3541556 ],\n",
       "          [0.273858  , 0.21198273, 0.22635981, 0.40452194, 0.21225491,\n",
       "           0.48606813, 0.19932765, 0.23868212],\n",
       "          [0.3943012 , 0.47304624, 0.26862285, 0.47427455, 0.60211563,\n",
       "           0.5168385 , 0.50502825, 0.34702405],\n",
       "          [0.30112642, 0.28722677, 0.2987135 , 0.48334852, 0.2866118 ,\n",
       "           0.27348912, 0.3967425 , 0.31689185],\n",
       "          [0.30987158, 0.14708327, 0.23801339, 0.3329318 , 0.15571085,\n",
       "           0.21191043, 0.2035982 , 0.23237891],\n",
       "          [0.4335206 , 0.27628022, 0.32084653, 0.499611  , 0.28662306,\n",
       "           0.30892092, 0.363936  , 0.34367642],\n",
       "          [0.3013934 , 0.41506758, 0.24529637, 0.34649193, 0.31687817,\n",
       "           0.28988478, 0.42230412, 0.3128063 ]]]], dtype=float32)>,\n",
       " 'embedding_sample': <tf.Tensor: shape=(1, 8), dtype=float32, numpy=\n",
       " array([[ 1.3232666 ,  0.21300374, -0.0584728 , -1.3286681 , -0.18778224,\n",
       "          0.21400708,  0.407911  , -0.29385394]], dtype=float32)>,\n",
       " 'mu': <tf.Tensor: shape=(1, 1, 10, 8), dtype=float32, numpy=\n",
       " array([[[[ 0.6002583 ,  0.64875764,  0.5107041 , -1.1787232 ,\n",
       "           -0.13511956,  0.02765517,  1.3224401 , -0.3857222 ],\n",
       "          [ 1.430979  ,  0.3844045 ,  0.39434063, -0.59683275,\n",
       "            0.05579299, -0.34556395,  0.5679105 , -0.1932686 ],\n",
       "          [ 0.1567817 ,  0.11424187,  0.38380057, -1.7696438 ,\n",
       "           -0.14112258,  0.44051653,  0.31136894, -0.47317567],\n",
       "          [ 0.80144787, -0.04703337,  0.19679372, -0.6222779 ,\n",
       "            0.13340342, -0.205149  ,  0.37757513, -0.02524494],\n",
       "          [ 0.7148527 , -0.00504168, -0.091415  , -1.9343919 ,\n",
       "            0.18050745, -0.25859526,  0.3518322 , -0.06685957],\n",
       "          [ 0.27491796, -0.11828785,  0.14466879, -1.4270186 ,\n",
       "            0.58885175,  0.09597553,  1.1455381 , -0.10378842],\n",
       "          [-0.04508518,  0.1453104 ,  0.4045161 , -1.6563884 ,\n",
       "           -0.31629622,  0.50878096,  0.46443388, -0.23068152],\n",
       "          [ 1.3232666 ,  0.21300374, -0.0584728 , -1.3286681 ,\n",
       "           -0.18778224,  0.21400708,  0.407911  , -0.29385394],\n",
       "          [ 0.76682204,  0.11500756,  0.23286885, -1.828588  ,\n",
       "           -0.64394605,  0.45314732, -0.09667996, -0.18327746],\n",
       "          [ 1.314671  ,  0.00496066,  0.2671154 , -0.51556027,\n",
       "            0.79963607, -0.36652195,  1.0904391 , -0.08658283]]]],\n",
       "       dtype=float32)>}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_embedding_result = predict_embedding(inp_pos=inp_pos_tensor, \n",
    "                                             target_pos=target_pos_tensor,\n",
    "                                             inp_embeddings=inp_embeddings_tensor)\n",
    "predict_embedding_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try the decode_stroke signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ConcreteFunction (*, embedding_sample: TensorSpec(shape=(None, 8), dtype=tf.float32, name='embedding_sample'), target_seq_len: TensorSpec(shape=(), dtype=tf.int32, name='target_seq_len')) -> Dict[['pen', TensorSpec(shape=(None, None, 1), dtype=tf.float32, name='pen')], ['seq_len', TensorSpec(shape=(None,), dtype=tf.int32, name='seq_len')], ['stroke', TensorSpec(shape=(None, None, 2), dtype=tf.float32, name='stroke')]] at 0x34B261CD0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_stroke = model.signatures[\"decode_stroke\"]\n",
    "decode_stroke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 17, 2), dtype=float32, numpy=\n",
       "array([[[ -0.32955068,  -0.22248104],\n",
       "        [ -0.6766161 ,  -0.49407703],\n",
       "        [ -2.0241368 ,  -5.802304  ],\n",
       "        [ -5.119701  , -15.102497  ],\n",
       "        [ -5.5239687 , -18.375616  ],\n",
       "        [ -2.6613305 , -17.858814  ],\n",
       "        [  0.9564642 , -16.767225  ],\n",
       "        [  3.9374683 , -15.174292  ],\n",
       "        [  5.4061937 , -11.872535  ],\n",
       "        [  6.628682  ,  -5.2172203 ],\n",
       "        [  4.7367835 ,   3.5651972 ],\n",
       "        [  4.209163  ,   2.217497  ],\n",
       "        [  1.1554601 ,   4.8128157 ],\n",
       "        [ -0.8442453 ,   3.380175  ],\n",
       "        [ -2.2247639 ,   2.0960534 ],\n",
       "        [ -2.9414732 ,  -0.9859777 ],\n",
       "        [ -2.8693335 ,  -1.7561842 ]]], dtype=float32)>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the (real) next stroke to determine the target_seq_len for the decoder\n",
    "target_seq_len_tensor = tf.convert_to_tensor(len(drawing_resampled[2]), dtype=tf.int32)\n",
    "\n",
    "decode_stroke_result = decode_stroke(embedding_sample = predict_embedding_result[\"embedding_sample\"],\n",
    "                                     target_seq_len = target_seq_len_tensor)\n",
    "\n",
    "decode_stroke_result[\"stroke\"]\n",
    "# This decoded stroke with pen state and stroke are used as the new input \n",
    "# for the encoder, whose starting position and embeddings will be used\n",
    "# for auto-regressive for the remaining stokes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Try Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def process_drawing_for_encode_stroke(drawing):\n",
    "#     flat_strokes = []\n",
    "#     total_points = 0\n",
    "#     for stroke in drawing:\n",
    "#         for i in range(len(stroke[0])):  # Iterate through points in the stroke\n",
    "#             x = stroke[0][i]\n",
    "#             y = stroke[1][i]\n",
    "#             # Assuming the third list contains timing information, not directly used here\n",
    "#             # If there's a specific \"pen state\" value needed, adjust accordingly\n",
    "#             flat_strokes.append([x, y, 1])  # Use '1' as a placeholder for pen state\n",
    "#         total_points += len(stroke[0])\n",
    "    \n",
    "#     # Convert to tensors\n",
    "#     input_stroke = tf.constant(flat_strokes, dtype=tf.float32)\n",
    "#     input_seq_len = tf.constant([total_points], dtype=tf.int32)\n",
    "    \n",
    "#     return input_stroke, input_seq_len\n",
    "\n",
    "# # Find the maximum sequence length across all processed drawings\n",
    "# max_seq_len = max(input_stroke.shape[0] for input_stroke, _ in processed_drawings)\n",
    "\n",
    "# # Pad each drawing sequence to the maximum length\n",
    "# padded_drawings = []\n",
    "# for input_stroke, input_seq_len in processed_drawings:\n",
    "#     # Calculate the padding amounts\n",
    "#     padding = [[0, max_seq_len - tf.shape(input_stroke)[0]], [0, 0]]  # Pad the sequence length to max_seq_len\n",
    "    \n",
    "#     # Pad the stroke data\n",
    "#     padded_stroke = tf.pad(input_stroke, padding, \"CONSTANT\")\n",
    "    \n",
    "#     # Append the padded stroke and original sequence length\n",
    "#     padded_drawings.append((padded_stroke, input_seq_len))\n",
    "\n",
    "# padded_drawings\n",
    "\n",
    "# import json\n",
    "\n",
    "# processed_drawings = []\n",
    "\n",
    "# # Draw a sample of 320 sketches\n",
    "# max_rows = 320\n",
    "# current_row = 0\n",
    "\n",
    "# with open(\"data_dir/quick_draw/raw_Eiffel_Tower.ndjson\", 'r') as f:\n",
    "#     for line in f:\n",
    "#         if current_row < max_rows:\n",
    "#             drawing_data = json.loads(line)\n",
    "#             drawing = drawing_data[\"drawing\"]\n",
    "#             processed_drawing = process_drawing_for_encode_stroke(drawing)\n",
    "#             processed_drawings.append(processed_drawing)\n",
    "#             current_row += 1\n",
    "#         else:\n",
    "#             break\n",
    "# stroke_tensors = [x[0] for x in padded_drawings]\n",
    "# seq_len_tensors = [x[1] for x in padded_drawings]\n",
    "\n",
    "# stroke_dataset = tf.data.Dataset.from_tensor_slices(stroke_tensors)\n",
    "# seq_len_dataset = tf.data.Dataset.from_tensor_slices(seq_len_tensors)\n",
    "\n",
    "# # Combine into a single dataset\n",
    "# dataset = tf.data.Dataset.zip((stroke_dataset, seq_len_dataset))\n",
    "\n",
    "# dataset\n",
    "\n",
    "# # Set your desired batch size\n",
    "# batch_size = 128\n",
    "\n",
    "# # Batch the dataset. No need to specify padding values or shapes here because\n",
    "# # your tensors within each dataset element already have a uniform shape after padding.\n",
    "# batched_dataset = dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the features of importance for input formatting\n",
    "# feature_description = {\n",
    "#     'ink': tf.io.VarLenFeature(tf.float32),\n",
    "# }\n",
    "\n",
    "# # For now, I use a very small sample of dataset\n",
    "# file_paths = \"data_dir/quick_draw/training/raw_Eiffel_Tower-00000-of-00010\"\n",
    "# dataset = tf.data.TFRecordDataset(file_paths)\n",
    "\n",
    "# # for raw_record in dataset.take(1):\n",
    "# #   example = tf.train.Example()\n",
    "# #   example.ParseFromString(raw_record.numpy())\n",
    "# #   print(example)\n",
    "\n",
    "# # Parse a Tensorflow Example proto \n",
    "# parsed_dataset = dataset.map(lambda x: tf.io.parse_single_example(x, feature_description)) \n",
    "\n",
    "# # Define a function to get the `input_seq_len` and `input_stroke` arguments \n",
    "# # for fitting the pretrained model (specifically, `encode_stroke` signature)\n",
    "# max_length_threshold = 201\n",
    "\n",
    "# def get_input_arguments(parsed_record):\n",
    "#     # Reshape and extract the first three dimensions from parsed_record['ink']\n",
    "#     # (x coordinate, y coordinate, and pen state)\n",
    "#     ink = tf.sparse.to_dense(parsed_record['ink'])\n",
    "#     input_seq_len = tf.shape(ink)[0] // 4\n",
    "#     ink_reshaped = tf.reshape(ink, (input_seq_len, 4))\n",
    "#     # Expand the input_stroke to three dimensions for batching \n",
    "#     input_stroke = tf.expand_dims(ink_reshaped[:, :3], axis=0)\n",
    "    \n",
    "#     # Make sure it matches the input shape \n",
    "#     input_seq_len = tf.reshape(input_seq_len, [1]) \n",
    "\n",
    "#     return input_seq_len, input_stroke\n",
    "    \n",
    "# preprocessed_dataset = parsed_dataset.map(get_input_arguments)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

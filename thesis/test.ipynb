{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import linecache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_signature_directory = '../thesis/model_architecture.csv'\n",
    "model = tf.saved_model.load(\"../pretrained_model/saved_model_with_signatures\")\n",
    "\n",
    "if not os.path.exists(model_signature_directory):\n",
    "    # Collecting signature details\n",
    "    signatures_data = []\n",
    "\n",
    "    # Iterate over each signature in the model\n",
    "    for key, signature in model.signatures.items():\n",
    "        # Initialize dictionaries for current signature's inputs and outputs\n",
    "        inputs_dict = {}\n",
    "        outputs_dict = {}\n",
    "\n",
    "        # Iterate over inputs and outputs, filling in the dictionaries\n",
    "        for input_key, input_val in signature.structured_input_signature[1].items():\n",
    "            inputs_dict[input_key] = str(input_val.dtype.name)\n",
    "\n",
    "        for output_key, output_val in signature.structured_outputs.items():\n",
    "            outputs_dict[output_key] = str(output_val.dtype.name)\n",
    "\n",
    "        # Append the current signature's details to the list\n",
    "        signatures_data.append({\n",
    "            \"Signature Key\": key,\n",
    "            \"Inputs\": inputs_dict,\n",
    "            \"Outputs\": outputs_dict\n",
    "        })\n",
    "\n",
    "    # Convert list of signature data into a DataFrame for visualization\n",
    "    df_signatures = pd.DataFrame(signatures_data)\n",
    "\n",
    "    df_inputs = df_signatures[\"Inputs\"].apply(pd.Series)\n",
    "    df_outputs = df_signatures[\"Outputs\"].apply(pd.Series)\n",
    "    df_signatures = pd.concat([df_signatures.drop(['Inputs', 'Outputs'], axis=1), df_inputs, df_outputs], axis=1)\n",
    "    df_signatures.set_index('Signature Key', drop=True, inplace=True)\n",
    "    df_signatures.to_csv(model_signature_directory, index=True)\n",
    "else:\n",
    "    df_signatures = pd.read_csv(model_signature_directory, index_col='Signature Key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_signatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess drawings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize sample drawing (first row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from PIL import Image, ImageDraw\n",
    "from IPython.display import display  \n",
    "\n",
    "# read ndjson lines\n",
    "#lines = open('data/raw_The_Eiffel_Tower.ndjson','r').readlines()\n",
    "lines = open('data/raw_cat.ndjson','r').readlines()\n",
    "# grab the first line, JSON parse it and fetch the 'drawing' array\n",
    "raw_drawing = json.loads(lines[0])['drawing']\n",
    "\n",
    "print('before',raw_drawing)\n",
    "# zip x,y coordinates for each point in every polyline\n",
    "polylines = list((zip(polyline[0], polyline[1]) for polyline in raw_drawing))\n",
    "# notice how the data is shuffled to (x1,y1),(x2,y2) order\n",
    "print('after',polylines)\n",
    "\n",
    "# make a new image\n",
    "pil_img = Image.new(\"RGB\", (1000, 1000), (255,255,255))\n",
    "# get a drawing context\n",
    "d = ImageDraw.Draw(pil_img)\n",
    "# render each polyline\n",
    "for polyline in polylines:\n",
    "    # Flatten the list of tuples into a single list of coordinates\n",
    "    polyline_flat = [coord for point in polyline for coord in point]\n",
    "    d.line(polyline_flat,fill=(0, 0, 0), width=3)\n",
    "\n",
    "# display image\n",
    "display(pil_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse preprocessed drawings into TFRecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type the following in the terminal to convert raw ndjson file to TFRecord \n",
    "# python thesis/data_preprocessing.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_function(example_proto):\n",
    "     # Define the feature structure of TF_example\n",
    "    feature_description = {\n",
    "        'key': tf.io.FixedLenFeature([], tf.string),\n",
    "        'label_id': tf.io.FixedLenFeature([], tf.string),\n",
    "        'ink': tf.io.VarLenFeature(tf.float32),\n",
    "        'stroke_length': tf.io.VarLenFeature(tf.int64),\n",
    "        'shape': tf.io.FixedLenFeature([3], tf.int64),\n",
    "        'num_strokes': tf.io.FixedLenFeature([], tf.int64)\n",
    "    }\n",
    "\n",
    "    # Parse the input tf.train.Example proto based on feature_description\n",
    "    return tf.io.parse_single_example(example_proto, feature_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfrecord_path = 'data/raw_The_Eiffel_Tower-00000-of-00001.tfrecord'\n",
    "tfrecord_path = 'data/raw_cat-00000-of-00001.tfrecord'\n",
    "raw_drawing_dataset = tf.data.TFRecordDataset(tfrecord_path)\n",
    "parsed_drawing_dataset = raw_drawing_dataset.map(_parse_function)\n",
    "\n",
    "parsed_drawing_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this code, I just sample the first record\n",
    "for parsed_features in parsed_drawing_dataset.take(1):\n",
    "    ink = tf.sparse.to_dense(parsed_features['ink'])\n",
    "    shape = parsed_features['shape']\n",
    "    stroke_length = tf.sparse.to_dense(parsed_features['stroke_length'])\n",
    "    \n",
    "    # Reshape ink data to original dimensions (num_strokes, max_len, 4)\n",
    "    reshaped_ink = tf.reshape(ink, shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Undo preprocessing and do visualization again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from undo_data_preprocessing import undo_preprocessing\n",
    "# lines = open('data/raw_The_Eiffel_Tower.ndjson','r').readlines()\n",
    "lines = open('data/raw_cat.ndjson','r').readlines()\n",
    "statistics_json_path = \"data/cat_statistics.json\"\n",
    "reversed_strokes = undo_preprocessing(reshaped_ink, stroke_length, raw_drawing, statistics_json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stroke_visualization import visualize_stroke\n",
    "visualize_stroke(reversed_strokes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Operationalize flexibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.expand_dims(reshaped_ink[:1, 0, :2], axis=0)\n",
    "tf.expand_dims(encoded_embedding_sample[:, :], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.linalg import det, inv\n",
    "from scipy.special import logsumexp\n",
    "import tensorflow as tf\n",
    "\n",
    "def calculate(model, reshaped_ink, stroke_length):\n",
    "    '''\n",
    "    Inputs: \n",
    "        1) model: pre-trained CoSE model\n",
    "        2) reshaped_ink: preprocessed (normalized) ink\n",
    "        3) stroke_length: length for each stroke\n",
    "    '''\n",
    "    \n",
    "    # Load signatures of pre-trained models\n",
    "    encode_stroke = model.signatures[\"encode_stroke\"]\n",
    "    predict_position = model.signatures[\"predict_position\"]\n",
    "    predict_embedding = model.signatures[\"predict_embedding\"]\n",
    "\n",
    "    # Get encoded vectors for each stroke\n",
    "    encoded_result = encode_stroke(\n",
    "        input_seq_len=tf.cast(stroke_length, tf.int32),\n",
    "        input_stroke=tf.gather(reshaped_ink, indices=[0, 1, 3], axis=2) # x coordinate, y coordinate, and pen state\n",
    "    )\n",
    "\n",
    "    encoded_embedding_sample = encoded_result['embedding_sample']\n",
    "\n",
    "    # Iterate through each stroke in the given drawing (ink) to predict the next stroke\n",
    "    n_stroke, _, _ = reshaped_ink.shape\n",
    "\n",
    "    # Initialize an numpy array to store entropy and bhattacharyya distance\n",
    "    entropy_array = np.zeros(n_stroke, dtype=float)\n",
    "    bhattacharyya_distance_array = np.zeros(n_stroke, dtype=float)\n",
    "\n",
    "    for i in range(n_stroke):\n",
    "        # Predict next starting position\n",
    "        input_position = tf.expand_dims(reshaped_ink[:i+1, 0, :2], axis=0)\n",
    "        input_embedding = tf.expand_dims(encoded_embedding_sample[:i+1, :], axis=0)\n",
    "        predict_position_result = predict_position(\n",
    "            inp_pos=input_position,\n",
    "            inp_embeddings=input_embedding\n",
    "        )\n",
    "        \n",
    "        # Predict the embedding of next stroke\n",
    "        predict_embedding_result = predict_embedding(\n",
    "            inp_pos=input_position, \n",
    "            target_pos=tf.expand_dims(predict_position_result['position_sample'], axis=0),\n",
    "            inp_embeddings=input_embedding\n",
    "        )\n",
    "        \n",
    "        # Calculate entropy and bhattacharyya distance\n",
    "        entropy_array[i] = entropy_gmm(predict_embedding_result)\n",
    "        bhattacharyya_distance_array[i] = bhattacharyya_distance(predict_embedding_result)\n",
    "\n",
    "    return entropy_array, bhattacharyya_distance_array\n",
    "\n",
    "\n",
    "def entropy_gmm(predict_result):\n",
    "    pi = predict_result['pi'].numpy().flatten()\n",
    "    mus = predict_result['mu'].numpy().squeeze()\n",
    "    sigmas = [np.diag(sigma) for sigma in predict_result['sigma'].numpy().squeeze()]\n",
    "\n",
    "    N = len(pi)\n",
    "    kl_matrix = np.zeros((N, N))\n",
    "\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            diff_mu = mus[j] - mus[i]\n",
    "            inv_sigma_j = inv(sigmas[j])\n",
    "            kl_matrix[i, j] = 0.5 * (np.trace(inv_sigma_j @ sigmas[i]) + diff_mu.T @ inv_sigma_j @ diff_mu - mus.shape[1] + np.log(det(sigmas[j]) / det(sigmas[i])))\n",
    "\n",
    "    log_terms = -0.5 * kl_matrix  # -1/2 factor from the exponent in the entropy formula\n",
    "    log_sum_exp = logsumexp(log_terms, b=pi, axis=1)\n",
    "    entropy = -np.sum(pi * log_sum_exp)\n",
    "    return entropy\n",
    "\n",
    "def bhattacharyya_distance(predict_result):\n",
    "    pi = predict_result['pi'].numpy().flatten()\n",
    "    mus = predict_result['mu'].numpy().squeeze()\n",
    "    sigmas = [np.diag(sigma) for sigma in predict_result['sigma'].numpy().squeeze()]\n",
    "\n",
    "    N = len(pi)\n",
    "    bc_values = []\n",
    "\n",
    "    for i in range(N):\n",
    "        for j in range(i+1, N):\n",
    "            sigma_i = sigmas[i]\n",
    "            sigma_j = sigmas[j]\n",
    "            sigma_avg = 0.5 * (sigma_i + sigma_j)\n",
    "            delta_mu = mus[j] - mus[i]\n",
    "            term = 0.25 * delta_mu.T @ inv(sigma_avg) @ delta_mu\n",
    "            bc = np.sqrt(det(sigma_i)**0.25 * det(sigma_j)**0.25 / det(sigma_avg)**0.5) * np.exp(-term)\n",
    "            bc_values.append(-np.log(bc))  # Convert BC to a distance\n",
    "\n",
    "    return np.mean(bc_values)\n",
    "\n",
    "calculate(model, reshaped_ink, stroke_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Visualize two measures via line chart\n",
    "entropy_array, bhattacharyya_distance_array = calculate(model, reshaped_ink, stroke_length)\n",
    "\n",
    "# Adjusting the plot to separate the two measures and modify x-axis labels\n",
    "\n",
    "# Indices now represent the number of strokes, assuming each index is a stroke\n",
    "number_of_strokes = np.arange(1, len(entropy_array) + 1)\n",
    "\n",
    "# Creating the figure and axes for subplots\n",
    "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(10, 12))\n",
    "fig.suptitle('Entropy and Bhattacharyya Distance Measures per Number of Input Strokes', fontsize=16)\n",
    "\n",
    "# Plotting Entropy\n",
    "axes[0].plot(number_of_strokes, entropy_array, label='Entropy', marker='o', linestyle='-', color='blue')\n",
    "axes[0].set_title('Entropy Over Number of Input Strokes')\n",
    "axes[0].set_xlabel('Number of Input Strokes')\n",
    "axes[0].set_ylabel('Entropy')\n",
    "axes[0].grid(True)\n",
    "axes[0].legend()\n",
    "\n",
    "# Plotting Bhattacharyya Distance\n",
    "axes[1].plot(number_of_strokes, bhattacharyya_distance_array, label='Bhattacharyya Distance', marker='s', linestyle='--', color='red')\n",
    "axes[1].set_title('Bhattacharyya Distance Over Number of Input Strokes')\n",
    "axes[1].set_xlabel('Number of Input Strokes')\n",
    "axes[1].set_ylabel('Bhattacharyya Distance')\n",
    "axes[1].grid(True)\n",
    "axes[1].legend()\n",
    "\n",
    "# Adjusting layout to prevent overlap of subplots\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "\n",
    "# Display the plots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use pretrained model for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped_ink[:1, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autoregresive_prediction(model, raw_drawing, reshaped_ink, stroke_length, n_starting_stroke):\n",
    "    '''\n",
    "    Inputs: \n",
    "        1) model: pre-trained CoSE model\n",
    "        2) raw_drawing: line in the ndjson file associated with the 'drawing' key\n",
    "        3) reshaped_ink: preprocessed (normalized) ink\n",
    "        4) stroke_length: length for each stroke\n",
    "    '''\n",
    "    \n",
    "    # Load signatures of pre-trained models\n",
    "    encode_stroke = model.signatures[\"encode_stroke\"]\n",
    "    predict_position = model.signatures[\"predict_position\"]\n",
    "    predict_embedding = model.signatures[\"predict_position\"]\n",
    "    decode_stroke = model.signatures[\"decode_stroke\"]\n",
    "\n",
    "    # Get encoded vectors for each stroke\n",
    "    encoded_result = encode_stroke(\n",
    "        input_seq_len=tf.cast(stroke_length, tf.int32),\n",
    "        input_stroke=tf.gather(reshaped_ink, indices=[0, 1, 3], axis=2) # x coordinate, y coordinate, and pen state\n",
    "    )\n",
    "\n",
    "    encoded_embedding_sample = encoded_result['embedding_sample']\n",
    "    # Define the starting stroke (for auto-regressive completion)\n",
    "    max_seq_len = reshaped_ink.shape[1]\n",
    "    starting_ink = reshaped_ink[:n_starting_stroke, :, :]\n",
    "\n",
    "    # Iterate through each stroke in the given drawing (ink) to predict the next stroke\n",
    "    n_stroke, max_stroke_length, stroke_dim = reshaped_ink.shape\n",
    "    for i in range(len(n_stroke)):\n",
    "\n",
    "        # Predict next starting position\n",
    "        input_position = tf.expand_dims(tf.expand_dims(reshaped_ink[i, 0, :2], axis=0), axis=0)\n",
    "        input_embedding = tf.expand_dims(tf.expand_dims(encoded_embedding_sample[i, :], axis=0), axis=0)\n",
    "        predict_position_result = predict_position(\n",
    "            inp_pos=input_position,\n",
    "            inp_embeddings=input_embedding\n",
    "        )\n",
    "        target_pos=tf.expand_dims(predict_position_result['position_sample'], axis=0)\n",
    "        # Predict the embedding of next stroke\n",
    "        predict_embedding_result = predict_embedding(\n",
    "            inp_pos=input_position, \n",
    "            target_pos=tf.expand_dims(predict_position_result['position_sample'], axis=0),\n",
    "            inp_embeddings=input_embedding\n",
    "        )\n",
    "        \n",
    "        # Decode the predicted embedding into normalied coordinates\n",
    "        decode_result = decode_stroke(\n",
    "            embedding_sample = predict_embedding_result['embedding_sample'],\n",
    "            target_seq_len = tf.cast(stroke_length[i + 1], tf.int32)\n",
    "        )\n",
    "\n",
    "        decoded_stroke = decode_result['stroke']\n",
    "        # "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try the forward_pass signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_pass = model.signatures[\"forward_pass\"]\n",
    "forward_pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_pass(input_seq_len=tf.cast(stroke_length[:2], tf.int32), \n",
    "             input_stroke=reshaped_ink[:2, :, :3],\n",
    "             target_seq_len=tf.cast(stroke_length[2], tf.int32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try the encode_stroke signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_stroke = model.signatures[\"encode_stroke\"]\n",
    "encode_stroke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_strokes = tf.gather(reshaped_ink, indices=[0, 1, 3], axis=2)\n",
    "encoded_result = encode_stroke(\n",
    "    input_seq_len=tf.cast(stroke_length, tf.int32),\n",
    "    input_stroke=selected_strokes\n",
    ")\n",
    "\n",
    "encoded_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_stroke = model.signatures[\"decode_stroke\"]\n",
    "decode_stroke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.expand_dims(encoded_result[\"embedding_sample\"][6, :], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the (real) next stroke to determine the target_seq_len for the decoder\n",
    "decode_result = decode_stroke(\n",
    "    embedding_sample = tf.expand_dims(encoded_result[\"embedding_sample\"][6, :], axis=0),\n",
    "    target_seq_len = tf.cast(stroke_length[6], tf.int32)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped_ink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_result['stroke']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_stroke = undo_preprocessing(decode_result['stroke'], decode_result['seq_len'], original_drawing)\n",
    "visualize_stroke(decoded_stroke)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(stroke_length)):\n",
    "    # Use the (real) next stroke to determine the target_seq_len for the decoder\n",
    "    decode_result = decode_stroke(\n",
    "        embedding_sample = tf.expand_dims(encoded_result[\"embedding_sample\"][i, :], axis=0),\n",
    "        target_seq_len = tf.cast(stroke_length[i], tf.int32)\n",
    "    )\n",
    "\n",
    "    decoded_stroke = undo_preprocessing(decode_result['stroke'], decode_result['seq_len'], original_drawing)\n",
    "    filtered_arrays  = []\n",
    "    for arr in decoded_stroke:\n",
    "        for sub_arr in arr:\n",
    "            if np.all(sub_arr >= 0):\n",
    "                filtered_arrays.append(sub_arr)\n",
    "\n",
    "    filtered_arrays = np.array(filtered_arrays)\n",
    "\n",
    "    visualize_stroke([filtered_arrays])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists to collect embeddings and positions\n",
    "embedding_sample_list = []\n",
    "inp_pos_list = []\n",
    "\n",
    "# Process only the first two strokes\n",
    "for stroke in drawing_resampled[:2]:\n",
    "    input_seq_len_tensor, input_stroke_tensor = formalize_input(stroke)\n",
    "    output = encode_stroke(input_seq_len=input_seq_len_tensor, \n",
    "                           input_stroke=input_stroke_tensor)\n",
    "    embedding_sample = output[\"embedding_sample\"]\n",
    "    \n",
    "    # Extract the first point's coordinates as position\n",
    "    inp_pos = [[stroke[0][0], stroke[1][0]]]\n",
    "    inp_pos_list.extend(inp_pos)\n",
    "    embedding_sample_list.append(embedding_sample)\n",
    "\n",
    "# Convert lists to tensors with the right shape\n",
    "inp_pos_tensor = tf.convert_to_tensor(inp_pos_list, dtype=tf.float32)  # Shape: (num_strokes, 2)\n",
    "inp_embeddings_tensor = tf.concat(embedding_sample_list, axis=0)  # Shape: (num_strokes, 8)\n",
    "\n",
    "# Add batch dimension\n",
    "inp_pos_tensor = tf.expand_dims(inp_pos_tensor, axis=0)  # Shape: (1, num_strokes, 2)\n",
    "inp_embeddings_tensor = tf.expand_dims(inp_embeddings_tensor, axis=0)  # Shape: (1, num_strokes, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try the predict_position signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_position = model.signatures[\"predict_position\"]\n",
    "predict_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_position_result = predict_position(\n",
    "    inp_pos=tf.expand_dims(reshaped_ink[:2, 0, :2], axis=0),\n",
    "    inp_embeddings=tf.expand_dims(encoded_result['embedding_sample'][:2, :], axis=0)\n",
    ")\n",
    "predict_position_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict_position_result = predict_position(\n",
    "#     inp_pos=tf.expand_dims(reshaped_ink[:, 0, :2], axis=1),\n",
    "#     inp_embeddings=tf.expand_dims(encoded_result['embedding_sample'], axis=1)\n",
    "# )\n",
    "# predict_position_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try predict_embedding signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_embedding = model.signatures[\"predict_embedding\"]\n",
    "predict_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_embedding_result = predict_embedding(inp_pos=tf.expand_dims(tf.expand_dims(reshaped_ink[0, 0, :2], axis=0), axis=0),\n",
    "                                             target_pos=tf.expand_dims(predict_position_result['position_sample'], axis=0),\n",
    "                                             inp_embeddings=tf.expand_dims(tf.expand_dims(encoded_result['embedding_sample'][0, :], axis=0), axis=0))\n",
    "predict_embedding_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict_embedding_result = predict_embedding(inp_pos=tf.expand_dims(reshaped_ink[:, 0, :2], axis=1), \n",
    "#                                              target_pos=tf.expand_dims(predict_position_result['position_sample'], axis=1),\n",
    "#                                              inp_embeddings=tf.expand_dims(encoded_result['embedding_sample'], axis=1))\n",
    "# predict_embedding_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try the decode_stroke signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_stroke = model.signatures[\"decode_stroke\"]\n",
    "decode_stroke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_embedding = predict_embedding_result['embedding_sample']\n",
    "decode_result = decode_stroke(\n",
    "    embedding_sample = predicted_embedding,\n",
    "    target_seq_len = tf.cast(stroke_length[1], tf.int32)\n",
    ")\n",
    "\n",
    "decode_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped_ink[1, :, :2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.expand_dims(predict_position_result['position_sample'], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the (real) next stroke to determine the target_seq_len for the decoder\n",
    "target_seq_len_tensor = tf.convert_to_tensor(len(drawing_resampled[2]), dtype=tf.int32)\n",
    "\n",
    "decode_stroke_result = decode_stroke(embedding_sample = predict_embedding_result[\"embedding_sample\"],\n",
    "                                     target_seq_len = target_seq_len_tensor)\n",
    "\n",
    "decode_stroke_result[\"stroke\"]\n",
    "# This decoded stroke with pen state and stroke are used as the new input \n",
    "# for the encoder, whose starting position and embeddings will be used\n",
    "# for auto-regressive for the remaining stokes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_stroke_result['pen']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def process_drawing_for_encode_stroke(drawing):\n",
    "#     flat_strokes = []\n",
    "#     total_points = 0\n",
    "#     for stroke in drawing:\n",
    "#         for i in range(len(stroke[0])):  # Iterate through points in the stroke\n",
    "#             x = stroke[0][i]\n",
    "#             y = stroke[1][i]\n",
    "#             # Assuming the third list contains timing information, not directly used here\n",
    "#             # If there's a specific \"pen state\" value needed, adjust accordingly\n",
    "#             flat_strokes.append([x, y, 1])  # Use '1' as a placeholder for pen state\n",
    "#         total_points += len(stroke[0])\n",
    "    \n",
    "#     # Convert to tensors\n",
    "#     input_stroke = tf.constant(flat_strokes, dtype=tf.float32)\n",
    "#     input_seq_len = tf.constant([total_points], dtype=tf.int32)\n",
    "    \n",
    "#     return input_stroke, input_seq_len\n",
    "\n",
    "# # Find the maximum sequence length across all processed drawings\n",
    "# max_seq_len = max(input_stroke.shape[0] for input_stroke, _ in processed_drawings)\n",
    "\n",
    "# # Pad each drawing sequence to the maximum length\n",
    "# padded_drawings = []\n",
    "# for input_stroke, input_seq_len in processed_drawings:\n",
    "#     # Calculate the padding amounts\n",
    "#     padding = [[0, max_seq_len - tf.shape(input_stroke)[0]], [0, 0]]  # Pad the sequence length to max_seq_len\n",
    "    \n",
    "#     # Pad the stroke data\n",
    "#     padded_stroke = tf.pad(input_stroke, padding, \"CONSTANT\")\n",
    "    \n",
    "#     # Append the padded stroke and original sequence length\n",
    "#     padded_drawings.append((padded_stroke, input_seq_len))\n",
    "\n",
    "# padded_drawings\n",
    "\n",
    "# import json\n",
    "\n",
    "# processed_drawings = []\n",
    "\n",
    "# # Draw a sample of 320 sketches\n",
    "# max_rows = 320\n",
    "# current_row = 0\n",
    "\n",
    "# with open(\"data_dir/quick_draw/raw_Eiffel_Tower.ndjson\", 'r') as f:\n",
    "#     for line in f:\n",
    "#         if current_row < max_rows:\n",
    "#             drawing_data = json.loads(line)\n",
    "#             drawing = drawing_data[\"drawing\"]\n",
    "#             processed_drawing = process_drawing_for_encode_stroke(drawing)\n",
    "#             processed_drawings.append(processed_drawing)\n",
    "#             current_row += 1\n",
    "#         else:\n",
    "#             break\n",
    "# stroke_tensors = [x[0] for x in padded_drawings]\n",
    "# seq_len_tensors = [x[1] for x in padded_drawings]\n",
    "\n",
    "# stroke_dataset = tf.data.Dataset.from_tensor_slices(stroke_tensors)\n",
    "# seq_len_dataset = tf.data.Dataset.from_tensor_slices(seq_len_tensors)\n",
    "\n",
    "# # Combine into a single dataset\n",
    "# dataset = tf.data.Dataset.zip((stroke_dataset, seq_len_dataset))\n",
    "\n",
    "# dataset\n",
    "\n",
    "# # Set your desired batch size\n",
    "# batch_size = 128\n",
    "\n",
    "# # Batch the dataset. No need to specify padding values or shapes here because\n",
    "# # your tensors within each dataset element already have a uniform shape after padding.\n",
    "# batched_dataset = dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the features of importance for input formatting\n",
    "# feature_description = {\n",
    "#     'ink': tf.io.VarLenFeature(tf.float32),\n",
    "# }\n",
    "\n",
    "# # For now, I use a very small sample of dataset\n",
    "# file_paths = \"data_dir/quick_draw/training/raw_Eiffel_Tower-00000-of-00010\"\n",
    "# dataset = tf.data.TFRecordDataset(file_paths)\n",
    "\n",
    "# # for raw_record in dataset.take(1):\n",
    "# #   example = tf.train.Example()\n",
    "# #   example.ParseFromString(raw_record.numpy())\n",
    "# #   print(example)\n",
    "\n",
    "# # Parse a Tensorflow Example proto \n",
    "# parsed_dataset = dataset.map(lambda x: tf.io.parse_single_example(x, feature_description)) \n",
    "\n",
    "# # Define a function to get the `input_seq_len` and `input_stroke` arguments \n",
    "# # for fitting the pretrained model (specifically, `encode_stroke` signature)\n",
    "# max_length_threshold = 201\n",
    "\n",
    "# def get_input_arguments(parsed_record):\n",
    "#     # Reshape and extract the first three dimensions from parsed_record['ink']\n",
    "#     # (x coordinate, y coordinate, and pen state)\n",
    "#     ink = tf.sparse.to_dense(parsed_record['ink'])\n",
    "#     input_seq_len = tf.shape(ink)[0] // 4\n",
    "#     ink_reshaped = tf.reshape(ink, (input_seq_len, 4))\n",
    "#     # Expand the input_stroke to three dimensions for batching \n",
    "#     input_stroke = tf.expand_dims(ink_reshaped[:, :3], axis=0)\n",
    "    \n",
    "#     # Make sure it matches the input shape \n",
    "#     input_seq_len = tf.reshape(input_seq_len, [1]) \n",
    "\n",
    "#     return input_seq_len, input_stroke\n",
    "    \n",
    "# preprocessed_dataset = parsed_dataset.map(get_input_arguments)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

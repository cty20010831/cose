{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Signature Key</th>\n",
       "      <th>embedding_sample</th>\n",
       "      <th>target_seq_len</th>\n",
       "      <th>inp_pos</th>\n",
       "      <th>target_pos</th>\n",
       "      <th>inp_embeddings</th>\n",
       "      <th>input_seq_len</th>\n",
       "      <th>input_stroke</th>\n",
       "      <th>pen</th>\n",
       "      <th>seq_len</th>\n",
       "      <th>stroke</th>\n",
       "      <th>pi</th>\n",
       "      <th>sigma</th>\n",
       "      <th>embedding_sample</th>\n",
       "      <th>mu</th>\n",
       "      <th>position_sample</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>decode_stroke</td>\n",
       "      <td>float32</td>\n",
       "      <td>int32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>float32</td>\n",
       "      <td>int32</td>\n",
       "      <td>float32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>predict_embedding</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>float32</td>\n",
       "      <td>float32</td>\n",
       "      <td>float32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>float32</td>\n",
       "      <td>float32</td>\n",
       "      <td>float32</td>\n",
       "      <td>float32</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>predict_position</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>float32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>float32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>float32</td>\n",
       "      <td>float32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>float32</td>\n",
       "      <td>float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>encode_stroke</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>int32</td>\n",
       "      <td>float32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>float32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>forward_pass</td>\n",
       "      <td>NaN</td>\n",
       "      <td>int32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>int32</td>\n",
       "      <td>float32</td>\n",
       "      <td>float32</td>\n",
       "      <td>int32</td>\n",
       "      <td>float32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>float32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Signature Key embedding_sample target_seq_len  inp_pos target_pos  \\\n",
       "0      decode_stroke          float32          int32      NaN        NaN   \n",
       "1  predict_embedding              NaN            NaN  float32    float32   \n",
       "2   predict_position              NaN            NaN  float32        NaN   \n",
       "3      encode_stroke              NaN            NaN      NaN        NaN   \n",
       "4       forward_pass              NaN          int32      NaN        NaN   \n",
       "\n",
       "  inp_embeddings input_seq_len input_stroke      pen seq_len   stroke  \\\n",
       "0            NaN           NaN          NaN  float32   int32  float32   \n",
       "1        float32           NaN          NaN      NaN     NaN      NaN   \n",
       "2        float32           NaN          NaN      NaN     NaN      NaN   \n",
       "3            NaN         int32      float32      NaN     NaN      NaN   \n",
       "4            NaN         int32      float32  float32   int32  float32   \n",
       "\n",
       "        pi    sigma embedding_sample       mu position_sample  \n",
       "0      NaN      NaN              NaN      NaN             NaN  \n",
       "1  float32  float32          float32  float32             NaN  \n",
       "2  float32  float32              NaN  float32         float32  \n",
       "3      NaN      NaN          float32      NaN             NaN  \n",
       "4      NaN      NaN          float32      NaN             NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.saved_model.load(\"pretrained_model/saved_model_with_signatures\")\n",
    "\n",
    "# Collecting signature details\n",
    "signatures_data = []\n",
    "\n",
    "# Iterate over each signature in the model\n",
    "for key, signature in model.signatures.items():\n",
    "    # Initialize dictionaries for current signature's inputs and outputs\n",
    "    inputs_dict = {}\n",
    "    outputs_dict = {}\n",
    "\n",
    "    # Iterate over inputs and outputs, filling in the dictionaries\n",
    "    for input_key, input_val in signature.structured_input_signature[1].items():\n",
    "        inputs_dict[input_key] = str(input_val.dtype.name)\n",
    "\n",
    "    for output_key, output_val in signature.structured_outputs.items():\n",
    "        outputs_dict[output_key] = str(output_val.dtype.name)\n",
    "\n",
    "    # Append the current signature's details to the list\n",
    "    signatures_data.append({\n",
    "        \"Signature Key\": key,\n",
    "        \"Inputs\": inputs_dict,\n",
    "        \"Outputs\": outputs_dict\n",
    "    })\n",
    "\n",
    "# Convert list of signature data into a DataFrame for visualization\n",
    "df_signatures = pd.DataFrame(signatures_data)\n",
    "\n",
    "df_inputs = df_signatures[\"Inputs\"].apply(pd.Series)\n",
    "df_outputs = df_signatures[\"Outputs\"].apply(pd.Series)\n",
    "df_expanded = pd.concat([df_signatures.drop(['Inputs', 'Outputs'], axis=1), df_inputs, df_outputs], axis=1)\n",
    "df_expanded.to_csv(\"pretrained_model/model_architecture.csv\", index=False)\n",
    "\n",
    "df_expanded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocesses raw drawings and get the right input format for `encode_stroke`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions to adjusts all drawings to have a consistent scale or size\n",
    "def get_bounding_box(drawing):\n",
    "    minx = 99999\n",
    "    miny = 99999\n",
    "    maxx = 0\n",
    "    maxy = 0\n",
    "\n",
    "    for s in drawing:\n",
    "      minx = min(minx, min(s[0]))\n",
    "      maxx = max(maxx, max(s[0]))\n",
    "      miny = min(miny, min(s[1]))\n",
    "      maxy = max(maxy, max(s[1]))\n",
    "    return (minx, miny, maxx, maxy)\n",
    "\n",
    "def size_normalization(drawing):\n",
    "  bb = get_bounding_box(drawing)\n",
    "  width, height = bb[2] - bb[0], bb[3] - bb[1]\n",
    "  offset_x, offset_y = bb[0], bb[1]\n",
    "  if height < 1e-6:\n",
    "    height = 1\n",
    "\n",
    "  size_normalized_drawing = [[[(x - offset_x) / height for x in stroke[0]],\n",
    "                              [(y - offset_y) / height for y in stroke[1]],\n",
    "                              [t for t in stroke[2]]]\n",
    "                             for stroke in drawing]\n",
    "\n",
    "  return size_normalized_drawing\n",
    "\n",
    "# Define a function to resample the ink to have uniform time steps\n",
    "# (Ensure that each point is separated by a constant time step)\n",
    "def resample_ink(drawing, timestep=20):\n",
    "    resampled_drawing = []\n",
    "    \n",
    "    for stroke in drawing:\n",
    "        # Initialize with the first point\n",
    "        resampled_stroke = [[stroke[0][0], stroke[1][0], stroke[2][0]]]  \n",
    "        \n",
    "        for i in range(1, len(stroke[0])):\n",
    "            x0, y0, t0 = stroke[0][i-1], stroke[1][i-1], stroke[2][i-1]\n",
    "            x1, y1, t1 = stroke[0][i], stroke[1][i], stroke[2][i]\n",
    "            distance = np.sqrt((x1 - x0)**2 + (y1 - y0)**2)\n",
    "            if distance == 0:\n",
    "                continue\n",
    "            else:\n",
    "                new_points = max(1, int(distance / timestep))\n",
    "                for j in range(1, new_points + 1):\n",
    "                    new_point = [x0 + j * (x1 - x0) / new_points,\n",
    "                                y0 + j * (y1 - y0) / new_points,\n",
    "                                t0 + j * (t1 - t0) / new_points]\n",
    "                    resampled_stroke.append(new_point)\n",
    "        \n",
    "        resampled_drawing.append(resampled_stroke)\n",
    "\n",
    "    return resampled_drawing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I try with the first drawing in quick_draw_Eiffel_Tower:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are totally 5 strokes in the sample drawing\n"
     ]
    }
   ],
   "source": [
    "ndjson_file_path = 'data_dir/quick_draw/raw_Eiffel_Tower.ndjson'\n",
    "\n",
    "with open(ndjson_file_path, 'r') as f:\n",
    "    first_line = f.readline().strip()\n",
    "    first_row = json.loads(first_line)\n",
    "\n",
    "sample_drawing = first_row[\"drawing\"]\n",
    "print(f\"There are totally {len(sample_drawing)} strokes in the sample drawing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[41, 95, 76, 23, 14]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sequence length for each stroke\n",
    "[len(i[0]) for i in sample_drawing]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the drawing\n",
    "drawing_normalized = size_normalization(sample_drawing)\n",
    "drawing_resampled = resample_ink(drawing_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[0.0,\n",
       "   0.05771836099577235,\n",
       "   0.09480277360999947,\n",
       "   0.12053340190025204,\n",
       "   0.13908714026701963,\n",
       "   0.1612243812842494,\n",
       "   0.1884583022101865,\n",
       "   0.21878779516224942,\n",
       "   0.2471063333367372,\n",
       "   0.2750094658465666,\n",
       "   0.30659171523755563,\n",
       "   0.34314535128716145,\n",
       "   0.387723137808792,\n",
       "   0.4311141156786563,\n",
       "   0.47286661046432926,\n",
       "   0.5077290454427539,\n",
       "   0.5356750616204352,\n",
       "   0.561590328623709,\n",
       "   0.582830848252029,\n",
       "   0.6048494109192533,\n",
       "   0.6230569862827093,\n",
       "   0.6421843597302388,\n",
       "   0.6654688583331367,\n",
       "   0.6886874091488746,\n",
       "   0.7100235555837479,\n",
       "   0.7336376925156002,\n",
       "   0.7580661412541236,\n",
       "   0.778535257895336,\n",
       "   0.8022450216337415,\n",
       "   0.8251470633138497,\n",
       "   0.8472480732908796,\n",
       "   0.8730215349455613,\n",
       "   0.8990621077747813,\n",
       "   0.9255048061650668,\n",
       "   0.9502431239874235,\n",
       "   0.9768342174746746,\n",
       "   1.0062307328459166,\n",
       "   1.0355316717140282,\n",
       "   1.064321628414351,\n",
       "   1.0916148570756519,\n",
       "   1.1014752333865023],\n",
       "  [0.941734350341105,\n",
       "   0.9453244050123739,\n",
       "   0.9520694903554002,\n",
       "   0.9594638922786409,\n",
       "   0.9717177054415678,\n",
       "   0.980239608281211,\n",
       "   0.9836615489138159,\n",
       "   0.9852769930304105,\n",
       "   0.9856890786691707,\n",
       "   0.9856890786691707,\n",
       "   0.9845912567721612,\n",
       "   0.981512184268681,\n",
       "   0.977216573790619,\n",
       "   0.9737979531839124,\n",
       "   0.9692913701510456,\n",
       "   0.9659089680086832,\n",
       "   0.9625694243824614,\n",
       "   0.9592133812335939,\n",
       "   0.9569518399558377,\n",
       "   0.9558474786138771,\n",
       "   0.9546771191813339,\n",
       "   0.9535298993232328,\n",
       "   0.9524090384586267,\n",
       "   0.9508100938646776,\n",
       "   0.9489739183292745,\n",
       "   0.9478200584193769,\n",
       "   0.9466463789609355,\n",
       "   0.9455288381222275,\n",
       "   0.9432672968444713,\n",
       "   0.9428321722381144,\n",
       "   0.941734350341105,\n",
       "   0.9397893181989785,\n",
       "   0.937580494908212,\n",
       "   0.9353189536304559,\n",
       "   0.9341684137464565,\n",
       "   0.9319366520949388,\n",
       "   0.9285772889201731,\n",
       "   0.9252245657972039,\n",
       "   0.9207641613063758,\n",
       "   0.9174344771510032,\n",
       "   0.912908175176438],\n",
       "  [0,\n",
       "   73,\n",
       "   89,\n",
       "   105,\n",
       "   123,\n",
       "   141,\n",
       "   156,\n",
       "   172,\n",
       "   193,\n",
       "   205,\n",
       "   223,\n",
       "   238,\n",
       "   255,\n",
       "   271,\n",
       "   288,\n",
       "   305,\n",
       "   323,\n",
       "   340,\n",
       "   356,\n",
       "   373,\n",
       "   390,\n",
       "   407,\n",
       "   426,\n",
       "   439,\n",
       "   456,\n",
       "   472,\n",
       "   488,\n",
       "   505,\n",
       "   522,\n",
       "   538,\n",
       "   554,\n",
       "   573,\n",
       "   589,\n",
       "   607,\n",
       "   625,\n",
       "   642,\n",
       "   656,\n",
       "   673,\n",
       "   690,\n",
       "   708,\n",
       "   740]],\n",
       " [[0.3263718258980431,\n",
       "   0.3263718258980431,\n",
       "   0.33319266819565596,\n",
       "   0.33922560798351536,\n",
       "   0.3417574547031512,\n",
       "   0.3438079982743914,\n",
       "   0.3549013366273356,\n",
       "   0.361676025534621,\n",
       "   0.3648342504737199,\n",
       "   0.369561690683952,\n",
       "   0.3751495960911826,\n",
       "   0.38127152263379865,\n",
       "   0.38633853609896857,\n",
       "   0.3914846768480459,\n",
       "   0.39820657231320744,\n",
       "   0.4036758119462882,\n",
       "   0.4081263066628443,\n",
       "   0.41643396722520737,\n",
       "   0.42537786547788276,\n",
       "   0.43441739053711126,\n",
       "   0.4412942708476122,\n",
       "   0.44910412873893396,\n",
       "   0.4580315274689637,\n",
       "   0.4670809623024641,\n",
       "   0.4780621994779209,\n",
       "   0.48605008118217874,\n",
       "   0.4925972728603024,\n",
       "   0.5037928026164621,\n",
       "   0.5139433290694475,\n",
       "   0.5239388706770937,\n",
       "   0.5274102595742127,\n",
       "   0.5335882744331395,\n",
       "   0.5431453714085306,\n",
       "   0.55219143591271,\n",
       "   0.5622859243528074,\n",
       "   0.5702408070117739,\n",
       "   0.5747209807477232,\n",
       "   0.5813143509678856,\n",
       "   0.5857121780008746,\n",
       "   0.5879077211880481,\n",
       "   0.5901066347045426,\n",
       "   0.5923055482210371,\n",
       "   0.5985000122991868,\n",
       "   0.6010944616283731,\n",
       "   0.6010944616283731,\n",
       "   0.6029142382479761,\n",
       "   0.6098669761199089,\n",
       "   0.6164801155851926,\n",
       "   0.6164801155851926,\n",
       "   0.6164801155851926,\n",
       "   0.6204460374308775,\n",
       "   0.6237888507795748,\n",
       "   0.6268382945670845,\n",
       "   0.6302371962320925,\n",
       "   0.6335734198324161,\n",
       "   0.6381228613814235,\n",
       "   0.6426261243883922,\n",
       "   0.6471162078986132,\n",
       "   0.6570260324739782,\n",
       "   0.6784578057154045,\n",
       "   0.6885489238261809,\n",
       "   0.6915983676136906,\n",
       "   0.6961346296659505,\n",
       "   0.7002521660276539,\n",
       "   0.7036279784216426,\n",
       "   0.7070071108415295,\n",
       "   0.7107883688224819,\n",
       "   0.7142136294809849,\n",
       "   0.7191850664430244,\n",
       "   0.7253762104952759,\n",
       "   0.7358135167610753,\n",
       "   0.7455321380267567,\n",
       "   0.7543145119891417,\n",
       "   0.7639507362484401,\n",
       "   0.770705630758893,\n",
       "   0.7765407774886952,\n",
       "   0.7800451654311056,\n",
       "   0.7834637860378122,\n",
       "   0.7835132846057492,\n",
       "   0.7869583145093734,\n",
       "   0.7879077413094172,\n",
       "   0.792852768974539,\n",
       "   0.7959450209747666,\n",
       "   0.7970758419170675,\n",
       "   0.7993142436203816,\n",
       "   0.804921968576156,\n",
       "   0.8133515143317218,\n",
       "   0.8204921857908626,\n",
       "   0.8247086186815946,\n",
       "   0.8327987169407792,\n",
       "   0.8383239442833254,\n",
       "   0.8461602114715647,\n",
       "   0.8562579193307149,\n",
       "   0.8639259718734449,\n",
       "   0.8703248690614483],\n",
       "  [0.9516244056713488,\n",
       "   0.9318442950108613,\n",
       "   0.9162345393059124,\n",
       "   0.8994477841166238,\n",
       "   0.8779896518817026,\n",
       "   0.8545568084852618,\n",
       "   0.8297294536047257,\n",
       "   0.8062175332278001,\n",
       "   0.7896714296127094,\n",
       "   0.7689814306424205,\n",
       "   0.7494848300722714,\n",
       "   0.725382749940227,\n",
       "   0.7113389397839357,\n",
       "   0.6887731261811558,\n",
       "   0.6581040348224437,\n",
       "   0.6269833193347292,\n",
       "   0.5973593318860367,\n",
       "   0.5753671785157302,\n",
       "   0.5530123374677549,\n",
       "   0.5335255963684551,\n",
       "   0.5125092287916871,\n",
       "   0.49086316296955795,\n",
       "   0.4664875328248697,\n",
       "   0.4394052767183737,\n",
       "   0.4119372939666125,\n",
       "   0.3867637509310535,\n",
       "   0.3692880400644628,\n",
       "   0.34513324194542855,\n",
       "   0.3222575592588153,\n",
       "   0.2973808064171875,\n",
       "   0.28309624407985307,\n",
       "   0.25840073447021417,\n",
       "   0.2364646191127955,\n",
       "   0.210430686335372,\n",
       "   0.18546489643556485,\n",
       "   0.1660836919170901,\n",
       "   0.15266288965094102,\n",
       "   0.13900470553306965,\n",
       "   0.1245322599119499,\n",
       "   0.10994114851668034,\n",
       "   0.09118959194014416,\n",
       "   0.0773237552933663,\n",
       "   0.06341174010454963,\n",
       "   0.04502941065063302,\n",
       "   0.029205312061558512,\n",
       "   0.013549377814570818,\n",
       "   0.0,\n",
       "   0.0186625195183568,\n",
       "   0.03514594506876302,\n",
       "   0.05492605572925048,\n",
       "   0.08931709733355138,\n",
       "   0.1231245689311071,\n",
       "   0.15255740337353868,\n",
       "   0.18226051810613852,\n",
       "   0.21133398489679975,\n",
       "   0.2328712444156284,\n",
       "   0.24962500055962558,\n",
       "   0.27279737283332467,\n",
       "   0.2900324321257175,\n",
       "   0.31606963462561655,\n",
       "   0.33910035246099185,\n",
       "   0.3673726869417295,\n",
       "   0.39191975115098004,\n",
       "   0.4099889417985878,\n",
       "   0.43300305950447204,\n",
       "   0.45427003873313243,\n",
       "   0.47236548776738974,\n",
       "   0.4898181596663837,\n",
       "   0.5080950028428979,\n",
       "   0.5270871606902092,\n",
       "   0.5465640423186598,\n",
       "   0.5646759908755627,\n",
       "   0.5855374239104141,\n",
       "   0.606936198106549,\n",
       "   0.6238152097730697,\n",
       "   0.6383997817233882,\n",
       "   0.6517051376344403,\n",
       "   0.6701204158302255,\n",
       "   0.6949939492528006,\n",
       "   0.7228575181206762,\n",
       "   0.7373398735160679,\n",
       "   0.7507969445499838,\n",
       "   0.765022148848532,\n",
       "   0.7817264064245921,\n",
       "   0.797405480246022,\n",
       "   0.8240361122235154,\n",
       "   0.8409711619029242,\n",
       "   0.8555919523175869,\n",
       "   0.8716632922292329,\n",
       "   0.8927225183221414,\n",
       "   0.9096048500145604,\n",
       "   0.9263619261844557,\n",
       "   0.9430496842378702,\n",
       "   0.9587979755689355,\n",
       "   0.9681078312217549],\n",
       "  [1563,\n",
       "   1623,\n",
       "   1655,\n",
       "   1689,\n",
       "   1724,\n",
       "   1756,\n",
       "   1790,\n",
       "   1824,\n",
       "   1857,\n",
       "   1906,\n",
       "   1940,\n",
       "   1972,\n",
       "   1989,\n",
       "   2005,\n",
       "   2025,\n",
       "   2040,\n",
       "   2056,\n",
       "   2074,\n",
       "   2089,\n",
       "   2106,\n",
       "   2124,\n",
       "   2142,\n",
       "   2157,\n",
       "   2173,\n",
       "   2190,\n",
       "   2206,\n",
       "   2225,\n",
       "   2256,\n",
       "   2289,\n",
       "   2324,\n",
       "   2340,\n",
       "   2374,\n",
       "   2406,\n",
       "   2440,\n",
       "   2472,\n",
       "   2506,\n",
       "   2573,\n",
       "   2724,\n",
       "   2825,\n",
       "   2871,\n",
       "   2922,\n",
       "   2972,\n",
       "   3005,\n",
       "   3041,\n",
       "   3072,\n",
       "   3142,\n",
       "   3255,\n",
       "   3409,\n",
       "   3432,\n",
       "   3460,\n",
       "   3489,\n",
       "   3505,\n",
       "   3524,\n",
       "   3540,\n",
       "   3555,\n",
       "   3572,\n",
       "   3590,\n",
       "   3617,\n",
       "   3634,\n",
       "   3658,\n",
       "   3672,\n",
       "   3689,\n",
       "   3706,\n",
       "   3724,\n",
       "   3741,\n",
       "   3758,\n",
       "   3772,\n",
       "   3788,\n",
       "   3806,\n",
       "   3824,\n",
       "   3839,\n",
       "   3856,\n",
       "   3873,\n",
       "   3890,\n",
       "   3906,\n",
       "   3924,\n",
       "   3943,\n",
       "   3977,\n",
       "   4012,\n",
       "   4041,\n",
       "   4062,\n",
       "   4086,\n",
       "   4096,\n",
       "   4105,\n",
       "   4122,\n",
       "   4155,\n",
       "   4188,\n",
       "   4222,\n",
       "   4255,\n",
       "   4289,\n",
       "   4324,\n",
       "   4364,\n",
       "   4396,\n",
       "   4424,\n",
       "   4508]],\n",
       " [[0.405492268539993,\n",
       "   0.41083947206960303,\n",
       "   0.4130614748571169,\n",
       "   0.41636474971557186,\n",
       "   0.4175647378640855,\n",
       "   0.42527237920048044,\n",
       "   0.42873717834922576,\n",
       "   0.4321261702399619,\n",
       "   0.43711078669874887,\n",
       "   0.4410964777895549,\n",
       "   0.44811838286770056,\n",
       "   0.4604645028112822,\n",
       "   0.4705556209220587,\n",
       "   0.478883050729543,\n",
       "   0.4820050320525864,\n",
       "   0.48645557707256515,\n",
       "   0.48871047829852493,\n",
       "   0.49096210980200927,\n",
       "   0.49318738231199866,\n",
       "   0.49544560356385664,\n",
       "   0.4965928737253804,\n",
       "   0.49774009358348154,\n",
       "   0.49889722321585456,\n",
       "   0.5022994449067608,\n",
       "   0.5057048860167199,\n",
       "   0.5077818137331664,\n",
       "   0.5090048911526994,\n",
       "   0.5112169841659413,\n",
       "   0.5157565159406767,\n",
       "   0.5217630464316185,\n",
       "   0.5279805997807877,\n",
       "   0.5364761436269362,\n",
       "   0.5447145866796638,\n",
       "   0.5492936569446415,\n",
       "   0.5618639289397754,\n",
       "   0.5775363627094088,\n",
       "   0.5898692528528203,\n",
       "   0.5997626282089622,\n",
       "   0.6088317819841612,\n",
       "   0.6142812020686981,\n",
       "   0.6164801155851926,\n",
       "   0.6170010075272533,\n",
       "   0.6112218988103392,\n",
       "   0.6098867453650301,\n",
       "   0.6076977416228075,\n",
       "   0.6065438817129101,\n",
       "   0.6065900602549488,\n",
       "   0.6054922886613621,\n",
       "   0.6054922886613621,\n",
       "   0.6057493894547828,\n",
       "   0.6065900602549488,\n",
       "   0.6091417013714172,\n",
       "   0.6117955087393897,\n",
       "   0.6202317448501745,\n",
       "   0.6325679550194843,\n",
       "   0.6543754948284811,\n",
       "   0.6713534533274532,\n",
       "   0.6790610946638481,\n",
       "   0.6860731402711445,\n",
       "   0.6929137518138786,\n",
       "   0.6996060185630697,\n",
       "   0.7065191676413374,\n",
       "   0.7131356271325193,\n",
       "   0.7256004128502508,\n",
       "   0.731059692405637,\n",
       "   0.7380849175096807,\n",
       "   0.7450013866138467,\n",
       "   0.7641518493323957,\n",
       "   0.7778495719405094,\n",
       "   0.7851780763800128,\n",
       "   0.793663760755312,\n",
       "   0.8037351096209673,\n",
       "   0.8138229580092682,\n",
       "   0.8207361573909586,\n",
       "   0.8219724143072391,\n",
       "   0.8230734556233014],\n",
       "  [0.915360869460455,\n",
       "   0.893556549070511,\n",
       "   0.8660589879062021,\n",
       "   0.852031576665711,\n",
       "   0.8352316419796751,\n",
       "   0.8164603161580177,\n",
       "   0.8026010189561908,\n",
       "   0.7821879906312893,\n",
       "   0.7620155132737402,\n",
       "   0.7452453582139428,\n",
       "   0.7179454895008457,\n",
       "   0.6944005700786288,\n",
       "   0.6663292480750012,\n",
       "   0.6411326660718455,\n",
       "   0.6176636042110605,\n",
       "   0.5976790604407194,\n",
       "   0.5754891140123555,\n",
       "   0.5538298686934787,\n",
       "   0.5344553042268004,\n",
       "   0.5166202257084395,\n",
       "   0.49963235743519546,\n",
       "   0.48176438047838854,\n",
       "   0.46286447910830947,\n",
       "   0.44467335296407634,\n",
       "   0.4242998631294172,\n",
       "   0.4046318284947058,\n",
       "   0.3850693304408195,\n",
       "   0.37111767615491503,\n",
       "   0.34718381066838006,\n",
       "   0.32698829434323423,\n",
       "   0.3018148519145206,\n",
       "   0.2848203938929029,\n",
       "   0.2698830943426105,\n",
       "   0.2539799187730512,\n",
       "   0.2403118248809079,\n",
       "   0.225737213008284,\n",
       "   0.2081493758124946,\n",
       "   0.1925198005590018,\n",
       "   0.17677482925383475,\n",
       "   0.1632419509619096,\n",
       "   0.14393655370144406,\n",
       "   0.12912782969957337,\n",
       "   0.15691891133533806,\n",
       "   0.20327688568290644,\n",
       "   0.26675457357461607,\n",
       "   0.3254091692978291,\n",
       "   0.3812978816272936,\n",
       "   0.43417995838196627,\n",
       "   0.47547423929026295,\n",
       "   0.5052861603261634,\n",
       "   0.5296487115809495,\n",
       "   0.5562563045908463,\n",
       "   0.5775363627094088,\n",
       "   0.5992746850087701,\n",
       "   0.6231162940180729,\n",
       "   0.6414359957107277,\n",
       "   0.6682611007203803,\n",
       "   0.6825720220512096,\n",
       "   0.6986862204789962,\n",
       "   0.7162542884296644,\n",
       "   0.7340992264188747,\n",
       "   0.7491782810143364,\n",
       "   0.762519955996578,\n",
       "   0.788547248722205,\n",
       "   0.8019549217950294,\n",
       "   0.8157120024419293,\n",
       "   0.8290239984047778,\n",
       "   0.8535249846788351,\n",
       "   0.8710699130550612,\n",
       "   0.8896203062442192,\n",
       "   0.9110685790082912,\n",
       "   0.9372409468049856,\n",
       "   0.9616957545370041,\n",
       "   0.9796462291070392,\n",
       "   0.9977351386963456,\n",
       "   1.0],\n",
       "  [6241,\n",
       "   6376,\n",
       "   6394,\n",
       "   6411,\n",
       "   6423,\n",
       "   6457,\n",
       "   6491,\n",
       "   6527,\n",
       "   6562,\n",
       "   6578,\n",
       "   6591,\n",
       "   6607,\n",
       "   6624,\n",
       "   6640,\n",
       "   6656,\n",
       "   6673,\n",
       "   6689,\n",
       "   6706,\n",
       "   6724,\n",
       "   6744,\n",
       "   6763,\n",
       "   6773,\n",
       "   6791,\n",
       "   6807,\n",
       "   6824,\n",
       "   6842,\n",
       "   6857,\n",
       "   6874,\n",
       "   6908,\n",
       "   6940,\n",
       "   6973,\n",
       "   7008,\n",
       "   7042,\n",
       "   7106,\n",
       "   7257,\n",
       "   7382,\n",
       "   7440,\n",
       "   7492,\n",
       "   7556,\n",
       "   7594,\n",
       "   7642,\n",
       "   7689,\n",
       "   7852,\n",
       "   7864,\n",
       "   7882,\n",
       "   7894,\n",
       "   7906,\n",
       "   7924,\n",
       "   7942,\n",
       "   7959,\n",
       "   7974,\n",
       "   7991,\n",
       "   8007,\n",
       "   8039,\n",
       "   8073,\n",
       "   8107,\n",
       "   8141,\n",
       "   8159,\n",
       "   8174,\n",
       "   8191,\n",
       "   8207,\n",
       "   8227,\n",
       "   8241,\n",
       "   8274,\n",
       "   8290,\n",
       "   8307,\n",
       "   8325,\n",
       "   8364,\n",
       "   8393,\n",
       "   8423,\n",
       "   8457,\n",
       "   8492,\n",
       "   8526,\n",
       "   8557,\n",
       "   8604,\n",
       "   8641]],\n",
       " [[0.47032819914803103,\n",
       "   0.4841445875302946,\n",
       "   0.5128224682048413,\n",
       "   0.5331630092976319,\n",
       "   0.5481596165832879,\n",
       "   0.566528766540457,\n",
       "   0.578996821980664,\n",
       "   0.5846176761297633,\n",
       "   0.5912967130787843,\n",
       "   0.612781254610623,\n",
       "   0.6353866067036453,\n",
       "   0.6491568668472928,\n",
       "   0.65869414427414,\n",
       "   0.6697314697659075,\n",
       "   0.6792423881992598,\n",
       "   0.6893599156069538,\n",
       "   0.7018312910730591,\n",
       "   0.7176257106427404,\n",
       "   0.7446090702202077,\n",
       "   0.7593254874414236,\n",
       "   0.7780275957534454,\n",
       "   0.79312309956813,\n",
       "   0.7988956185366705],\n",
       "  [0.52855088968394,\n",
       "   0.52855088968394,\n",
       "   0.5274498483678778,\n",
       "   0.5255872132321342,\n",
       "   0.5199465898379139,\n",
       "   0.49971485504842383,\n",
       "   0.4771028629036051,\n",
       "   0.46370182988257724,\n",
       "   0.4492194744871855,\n",
       "   0.4281338894007821,\n",
       "   0.4192295799417718,\n",
       "   0.4263437918005723,\n",
       "   0.44312722696396256,\n",
       "   0.46812269588316285,\n",
       "   0.4956598961445596,\n",
       "   0.518614756418503,\n",
       "   0.5353025144719175,\n",
       "   0.5447409456731587,\n",
       "   0.5545452839711212,\n",
       "   0.5541925563711473,\n",
       "   0.5519013360739979,\n",
       "   0.5516276854545088,\n",
       "   0.5516276854545088],\n",
       "  [9001,\n",
       "   9091,\n",
       "   9107,\n",
       "   9126,\n",
       "   9142,\n",
       "   9175,\n",
       "   9207,\n",
       "   9224,\n",
       "   9244,\n",
       "   9286,\n",
       "   9321,\n",
       "   9344,\n",
       "   9353,\n",
       "   9365,\n",
       "   9383,\n",
       "   9395,\n",
       "   9407,\n",
       "   9424,\n",
       "   9460,\n",
       "   9475,\n",
       "   9491,\n",
       "   9511,\n",
       "   9551]],\n",
       " [[0.325274029152745,\n",
       "   0.37224849709721586,\n",
       "   0.4082450227404168,\n",
       "   0.4467305114354016,\n",
       "   0.4772677072197937,\n",
       "   0.5078312619976807,\n",
       "   0.5338882840461237,\n",
       "   0.5632782096689919,\n",
       "   0.5896681900722875,\n",
       "   0.6158174685979626,\n",
       "   0.6344140906325821,\n",
       "   0.6524172831896072,\n",
       "   0.6659468917590569,\n",
       "   0.6819489638576447],\n",
       "  [0.6988774740921024,\n",
       "   0.6966818302980835,\n",
       "   0.6955807889820212,\n",
       "   0.6943906100009342,\n",
       "   0.6921884267619641,\n",
       "   0.6909918089427715,\n",
       "   0.6888061252264471,\n",
       "   0.6865082648775014,\n",
       "   0.6802182242962211,\n",
       "   0.6724743141920594,\n",
       "   0.666098556578498,\n",
       "   0.6615985129905823,\n",
       "   0.6560040681384006,\n",
       "   0.649895321092532],\n",
       "  [9812,\n",
       "   9861,\n",
       "   9875,\n",
       "   9894,\n",
       "   9911,\n",
       "   9925,\n",
       "   9944,\n",
       "   9958,\n",
       "   9977,\n",
       "   9992,\n",
       "   10009,\n",
       "   10025,\n",
       "   10043,\n",
       "   10076]]]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drawing_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the input format and shape:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to formalize the input shape to be used in `encode_stroke` signature\n",
    "# Specifically, the shape of `input_seq_len` is (None, ) and the shape of input_stroke is (None, None, 3) \n",
    "def formalize_input(stroke):\n",
    "    input_stroke_tensor = tf.convert_to_tensor([stroke], dtype=tf.float32) # Add an extra dimension for batch size\n",
    "    input_seq_len_tensor = tf.convert_to_tensor([len(stroke)], dtype=tf.int32)\n",
    "\n",
    "    return input_seq_len_tensor, input_stroke_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use pretrained model for prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try the encode_stroke signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ConcreteFunction (*, input_seq_len: TensorSpec(shape=(None,), dtype=tf.int32, name='input_seq_len'), input_stroke: TensorSpec(shape=(None, None, 3), dtype=tf.float32, name='input_stroke')) -> Dict[['embedding_sample', TensorSpec(shape=(None, 8), dtype=tf.float32, name='embedding_sample')]] at 0x2F1DCF9A0>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode_stroke = model.signatures[\"encode_stroke\"]\n",
    "encode_stroke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists to collect embeddings and positions\n",
    "embedding_sample_list = []\n",
    "inp_pos_list = []\n",
    "\n",
    "# Process only the first two strokes\n",
    "for stroke in drawing_resampled[:2]:\n",
    "    input_seq_len_tensor, input_stroke_tensor = formalize_input(stroke)\n",
    "    output = encode_stroke(input_seq_len=input_seq_len_tensor, \n",
    "                           input_stroke=input_stroke_tensor)\n",
    "    embedding_sample = output[\"embedding_sample\"]\n",
    "    \n",
    "    # Extract the first point's coordinates as position\n",
    "    inp_pos = [[stroke[0][0], stroke[1][0]]]\n",
    "    inp_pos_list.extend(inp_pos)\n",
    "    embedding_sample_list.append(embedding_sample)\n",
    "\n",
    "# Convert lists to tensors with the right shape\n",
    "inp_pos_tensor = tf.convert_to_tensor(inp_pos_list, dtype=tf.float32)  # Shape: (num_strokes, 2)\n",
    "inp_embeddings_tensor = tf.concat(embedding_sample_list, axis=0)  # Shape: (num_strokes, 8)\n",
    "\n",
    "# Add batch dimension\n",
    "inp_pos_tensor = tf.expand_dims(inp_pos_tensor, axis=0)  # Shape: (1, num_strokes, 2)\n",
    "inp_embeddings_tensor = tf.expand_dims(inp_embeddings_tensor, axis=0)  # Shape: (1, num_strokes, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try the predict_position signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ConcreteFunction (*, inp_pos: TensorSpec(shape=(None, None, 2), dtype=tf.float32, name='inp_pos'), inp_embeddings: TensorSpec(shape=(None, None, 8), dtype=tf.float32, name='inp_embeddings')) -> Dict[['position_sample', TensorSpec(shape=(None, 2), dtype=tf.float32, name='position_sample')], ['pi', TensorSpec(shape=(None, 10), dtype=tf.float32, name='pi')], ['sigma', TensorSpec(shape=(None, 1, 10, 2), dtype=tf.float32, name='sigma')], ['mu', TensorSpec(shape=(None, 1, 10, 2), dtype=tf.float32, name='mu')]] at 0x2F3B70A30>"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_position = model.signatures[\"predict_position\"]\n",
    "predict_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'position_sample': <tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[ 6.838819 , -1.4229445]], dtype=float32)>,\n",
       " 'pi': <tf.Tensor: shape=(1, 10), dtype=float32, numpy=\n",
       " array([[3.6635324e-08, 1.1230591e-07, 1.7465905e-07, 5.0777880e-09,\n",
       "         2.5925906e-03, 2.6572111e-06, 9.4617978e-02, 3.7509776e-07,\n",
       "         9.0278608e-01, 5.3436561e-10]], dtype=float32)>,\n",
       " 'sigma': <tf.Tensor: shape=(1, 1, 10, 2), dtype=float32, numpy=\n",
       " array([[[[ 9.514327  ,  3.9390216 ],\n",
       "          [ 2.0930994 ,  4.950522  ],\n",
       "          [ 5.1820283 ,  1.2394203 ],\n",
       "          [28.916815  ,  3.907423  ],\n",
       "          [ 0.23929727,  0.6537428 ],\n",
       "          [ 1.112262  ,  0.4390132 ],\n",
       "          [18.509413  ,  1.1268417 ],\n",
       "          [33.872047  ,  2.2025366 ],\n",
       "          [21.131636  ,  5.791792  ],\n",
       "          [ 3.5448177 ,  1.1053672 ]]]], dtype=float32)>,\n",
       " 'mu': <tf.Tensor: shape=(1, 1, 10, 2), dtype=float32, numpy=\n",
       " array([[[[-0.25956464,  2.251717  ],\n",
       "          [ 0.11476465,  1.4058719 ],\n",
       "          [ 0.04891471,  0.40180525],\n",
       "          [-1.7153677 , -0.011313  ],\n",
       "          [ 3.1856074 , -0.11828808],\n",
       "          [ 0.4791981 ,  0.11125332],\n",
       "          [ 4.620057  , -0.9445043 ],\n",
       "          [ 0.39626926, -2.4041018 ],\n",
       "          [ 6.838819  , -1.4229445 ],\n",
       "          [-1.4030815 ,  0.86071765]]]], dtype=float32)>}"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_position_result = predict_position(inp_pos=inp_pos_tensor, \n",
    "                                           inp_embeddings=inp_embeddings_tensor)\n",
    "predict_position_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_pos = predict_position_result['position_sample']\n",
    "target_pos_tensor = tf.expand_dims(target_pos, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try predict_embedding signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ConcreteFunction (*, inp_pos: TensorSpec(shape=(None, None, 2), dtype=tf.float32, name='inp_pos'), target_pos: TensorSpec(shape=(None, 1, 2), dtype=tf.float32, name='target_pos'), inp_embeddings: TensorSpec(shape=(None, None, 8), dtype=tf.float32, name='inp_embeddings')) -> Dict[['pi', TensorSpec(shape=(None, 10), dtype=tf.float32, name='pi')], ['sigma', TensorSpec(shape=(None, 1, 10, 8), dtype=tf.float32, name='sigma')], ['embedding_sample', TensorSpec(shape=(None, 8), dtype=tf.float32, name='embedding_sample')], ['mu', TensorSpec(shape=(None, 1, 10, 8), dtype=tf.float32, name='mu')]] at 0x30F5F9A00>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_embedding = model.signatures[\"predict_embedding\"]\n",
    "predict_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pi': <tf.Tensor: shape=(1, 10), dtype=float32, numpy=\n",
       " array([[0.1571875 , 0.10592218, 0.07599134, 0.07578772, 0.07643081,\n",
       "         0.03154781, 0.05140919, 0.30794448, 0.0118671 , 0.10591192]],\n",
       "       dtype=float32)>,\n",
       " 'sigma': <tf.Tensor: shape=(1, 1, 10, 8), dtype=float32, numpy=\n",
       " array([[[[0.3948015 , 0.22166586, 0.12100061, 0.27087203, 0.17374739,\n",
       "           0.16457334, 0.33858636, 0.18659966],\n",
       "          [0.35628676, 0.2805058 , 0.32534322, 0.26516148, 0.23701735,\n",
       "           0.33111304, 0.36097148, 0.26723394],\n",
       "          [0.34547696, 0.39308548, 0.26500902, 0.46635893, 0.48166293,\n",
       "           0.42072284, 0.45070317, 0.21530402],\n",
       "          [0.46005574, 0.35597256, 0.24866836, 0.55371296, 0.2796112 ,\n",
       "           0.21513234, 0.5900684 , 0.41165432],\n",
       "          [0.23593482, 0.18024899, 0.18565036, 0.3458232 , 0.18754844,\n",
       "           0.4380323 , 0.17873028, 0.20960614],\n",
       "          [0.35366374, 0.3891411 , 0.250027  , 0.41915718, 0.461722  ,\n",
       "           0.37093452, 0.4005495 , 0.2734264 ],\n",
       "          [0.2587044 , 0.31366685, 0.2975046 , 0.45404217, 0.26829597,\n",
       "           0.28263843, 0.3548683 , 0.3073701 ],\n",
       "          [0.2835172 , 0.1547956 , 0.21098228, 0.25284493, 0.13137007,\n",
       "           0.15082495, 0.21969597, 0.1968965 ],\n",
       "          [0.4825237 , 0.25075206, 0.32375297, 0.5240865 , 0.25607562,\n",
       "           0.3158401 , 0.38428926, 0.3333331 ],\n",
       "          [0.29025173, 0.33856276, 0.25178128, 0.3486892 , 0.28702223,\n",
       "           0.27646276, 0.37073576, 0.27348906]]]], dtype=float32)>,\n",
       " 'embedding_sample': <tf.Tensor: shape=(1, 8), dtype=float32, numpy=\n",
       " array([[ 1.5297613 ,  0.15347895,  0.03754661, -1.0408332 , -0.15311435,\n",
       "          0.03770886,  0.6365748 , -0.23677462]], dtype=float32)>,\n",
       " 'mu': <tf.Tensor: shape=(1, 1, 10, 8), dtype=float32, numpy=\n",
       " array([[[[ 0.9237085 ,  0.54545856,  0.4525127 , -1.0009153 ,\n",
       "           -0.11345875,  0.07950111,  1.3406665 , -0.39866805],\n",
       "          [ 1.3215117 ,  0.46457568,  0.5227748 , -0.6423114 ,\n",
       "            0.18170038, -0.6191044 ,  0.8266284 , -0.12125202],\n",
       "          [ 0.11907297,  0.06986625,  0.30635926, -1.8316026 ,\n",
       "           -0.03685401,  0.40659356,  0.48966968, -0.4260399 ],\n",
       "          [ 0.8947925 , -0.01337566,  0.19991486, -0.64084214,\n",
       "            0.13021684, -0.14935383,  0.48972967, -0.0692564 ],\n",
       "          [ 0.76995957, -0.04033102, -0.04478991, -1.8276982 ,\n",
       "            0.27040553, -0.52206093,  0.4162336 , -0.06516724],\n",
       "          [ 0.25926703, -0.14337988,  0.19117758, -1.468057  ,\n",
       "            0.6325069 ,  0.05030696,  1.1684556 , -0.0667362 ],\n",
       "          [-0.12335961,  0.1537297 ,  0.43845546, -1.7297412 ,\n",
       "           -0.25132963,  0.45012346,  0.5422005 , -0.20101301],\n",
       "          [ 1.5297613 ,  0.15347895,  0.03754661, -1.0408332 ,\n",
       "           -0.15311435,  0.03770886,  0.6365748 , -0.23677462],\n",
       "          [ 0.74398047,  0.10074626,  0.2741709 , -1.8517408 ,\n",
       "           -0.6331098 ,  0.41044465, -0.08064331, -0.1276801 ],\n",
       "          [ 1.3041538 , -0.0331471 ,  0.32196033, -0.53905475,\n",
       "            0.7881019 , -0.3619079 ,  1.1379577 , -0.04284936]]]],\n",
       "       dtype=float32)>}"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_embedding_result = predict_embedding(inp_pos = inp_pos_tensor, \n",
    "                                             target_pos=target_pos_tensor,\n",
    "                                             inp_embeddings=inp_embeddings_tensor)\n",
    "predict_embedding_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try the decode_stroke signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ConcreteFunction (*, embedding_sample: TensorSpec(shape=(None, 8), dtype=tf.float32, name='embedding_sample'), target_seq_len: TensorSpec(shape=(), dtype=tf.int32, name='target_seq_len')) -> Dict[['pen', TensorSpec(shape=(None, None, 1), dtype=tf.float32, name='pen')], ['seq_len', TensorSpec(shape=(None,), dtype=tf.int32, name='seq_len')], ['stroke', TensorSpec(shape=(None, None, 2), dtype=tf.float32, name='stroke')]] at 0x2F01A62B0>"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_stroke = model.signatures[\"decode_stroke\"]\n",
    "decode_stroke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 76, 2), dtype=float32, numpy=\n",
       "array([[[ -0.28265634,  -0.2638566 ],\n",
       "        [ -0.15693945,  -0.02932076],\n",
       "        [ -0.15595943,  -0.10539629],\n",
       "        [ -0.43970346,  -0.18493247],\n",
       "        [ -0.6928278 ,  -0.48688692],\n",
       "        [ -0.9503494 ,  -1.1250703 ],\n",
       "        [ -1.4586362 ,  -1.9195957 ],\n",
       "        [ -2.0512776 ,  -2.8667626 ],\n",
       "        [ -2.7315304 ,  -4.113566  ],\n",
       "        [ -3.5267816 ,  -5.344566  ],\n",
       "        [ -6.230611  ,  -9.002508  ],\n",
       "        [ -6.9633293 , -10.03128   ],\n",
       "        [ -7.7016783 , -11.002031  ],\n",
       "        [ -8.42174   , -11.986371  ],\n",
       "        [ -9.10001   , -13.03823   ],\n",
       "        [ -9.756411  , -13.865174  ],\n",
       "        [-10.327514  , -14.504483  ],\n",
       "        [-10.806738  , -14.917845  ],\n",
       "        [-11.2465515 , -15.183992  ],\n",
       "        [-11.576551  , -15.289197  ],\n",
       "        [-11.713126  , -15.258755  ],\n",
       "        [-11.656347  , -15.121748  ],\n",
       "        [-11.376671  , -14.850074  ],\n",
       "        [-11.012295  , -14.446777  ],\n",
       "        [-10.598457  , -14.021563  ],\n",
       "        [-10.199151  , -13.595842  ],\n",
       "        [ -9.758249  , -13.198245  ],\n",
       "        [ -9.337325  , -12.658567  ],\n",
       "        [ -8.806844  , -12.108338  ],\n",
       "        [ -8.174672  , -11.554012  ],\n",
       "        [ -7.5209727 , -11.120142  ],\n",
       "        [ -6.8400235 , -10.724442  ],\n",
       "        [ -6.1789064 , -10.117692  ],\n",
       "        [ -5.5179834 ,  -9.521262  ],\n",
       "        [ -4.7967787 ,  -8.982463  ],\n",
       "        [ -3.9754503 ,  -8.244932  ],\n",
       "        [ -1.8656596 ,  -3.3452737 ],\n",
       "        [ -1.1899248 ,  -2.2808104 ],\n",
       "        [ -0.5368303 ,  -1.2698839 ],\n",
       "        [  0.01635838,  -0.34151676],\n",
       "        [  0.45092785,   0.50864714],\n",
       "        [  0.8277877 ,   1.1974223 ],\n",
       "        [  1.1378139 ,   1.872114  ],\n",
       "        [  1.5125455 ,   2.525674  ],\n",
       "        [  1.8315789 ,   3.2793903 ],\n",
       "        [  2.1569586 ,   4.061016  ],\n",
       "        [  2.1162968 ,   4.7535377 ],\n",
       "        [  2.2338433 ,   5.145102  ],\n",
       "        [  2.198205  ,   7.7129602 ],\n",
       "        [  2.199596  ,   7.9366217 ],\n",
       "        [  2.149082  ,   8.169273  ],\n",
       "        [  2.0629363 ,   8.381457  ],\n",
       "        [  1.9045702 ,   8.495547  ],\n",
       "        [  1.8099929 ,   6.551908  ],\n",
       "        [  1.3732572 ,   7.8510866 ],\n",
       "        [  0.40454972,   7.8748517 ],\n",
       "        [ -0.09095162,   4.287393  ],\n",
       "        [ -0.40136856,   3.9776502 ],\n",
       "        [ -0.7146325 ,   3.7046914 ],\n",
       "        [ -0.98452055,   3.4213002 ],\n",
       "        [ -1.1881374 ,   3.213882  ],\n",
       "        [ -1.2996099 ,   3.0381708 ],\n",
       "        [ -1.3681206 ,   2.8884091 ],\n",
       "        [ -1.4518328 ,   2.6571226 ],\n",
       "        [ -2.2309864 ,   2.6252906 ],\n",
       "        [ -2.4424558 ,   2.191262  ],\n",
       "        [ -2.6117103 ,   1.7416301 ],\n",
       "        [ -2.7612467 ,   1.3021693 ],\n",
       "        [ -2.8693318 ,   0.90434283],\n",
       "        [ -2.9470298 ,   0.57848954],\n",
       "        [ -4.1884546 ,  -0.94923615],\n",
       "        [ -4.2454915 ,  -1.0888073 ],\n",
       "        [ -4.2540965 ,  -1.2422905 ],\n",
       "        [ -4.2483077 ,  -1.372845  ],\n",
       "        [ -4.1768675 ,  -1.5388622 ],\n",
       "        [ -4.1040835 ,  -1.6668533 ]]], dtype=float32)>"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the (real) next stroke to determine the target_seq_len for the decoder\n",
    "target_seq_len_tensor = tf.convert_to_tensor(len(drawing_resampled[2]), dtype=tf.int32)\n",
    "\n",
    "decode_stroke_result = decode_stroke(embedding_sample = predict_embedding_result[\"embedding_sample\"],\n",
    "                                     target_seq_len = target_seq_len_tensor)\n",
    "\n",
    "decode_stroke_result[\"stroke\"]\n",
    "# This decoded stroke with pen state and stroke are used as the new input \n",
    "# for the encoder, whose starting position and embeddings will be used\n",
    "# for auto-regressive for the remaining stokes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[<tf.Tensor: shape=(), dtype=float32, numpy=-81.79892>,\n",
       "  <tf.Tensor: shape=(), dtype=float32, numpy=-15.237579>],\n",
       " [<tf.Tensor: shape=(), dtype=float32, numpy=-37.231617>,\n",
       "  <tf.Tensor: shape=(), dtype=float32, numpy=63.567722>],\n",
       " [<tf.Tensor: shape=(), dtype=float32, numpy=-51.91903>,\n",
       "  <tf.Tensor: shape=(), dtype=float32, numpy=56.075348>],\n",
       " [<tf.Tensor: shape=(), dtype=float32, numpy=-143.01344>,\n",
       "  <tf.Tensor: shape=(), dtype=float32, numpy=22.645748>],\n",
       " [<tf.Tensor: shape=(), dtype=float32, numpy=-220.10928>,\n",
       "  <tf.Tensor: shape=(), dtype=float32, numpy=-63.165787>],\n",
       " [<tf.Tensor: shape=(), dtype=float32, numpy=-286.36203>,\n",
       "  <tf.Tensor: shape=(), dtype=float32, numpy=-246.46031>],\n",
       " [<tf.Tensor: shape=(), dtype=float32, numpy=-407.363>,\n",
       "  <tf.Tensor: shape=(), dtype=float32, numpy=-523.14746>],\n",
       " [<tf.Tensor: shape=(), dtype=float32, numpy=-577.9726>,\n",
       "  <tf.Tensor: shape=(), dtype=float32, numpy=-824.4982>],\n",
       " [<tf.Tensor: shape=(), dtype=float32, numpy=-759.6229>,\n",
       "  <tf.Tensor: shape=(), dtype=float32, numpy=-1197.743>],\n",
       " [<tf.Tensor: shape=(), dtype=float32, numpy=-965.1646>,\n",
       "  <tf.Tensor: shape=(), dtype=float32, numpy=-1585.3662>],\n",
       " [<tf.Tensor: shape=(), dtype=float32, numpy=-1803.3162>,\n",
       "  <tf.Tensor: shape=(), dtype=float32, numpy=-2779.2876>],\n",
       " [<tf.Tensor: shape=(), dtype=float32, numpy=-2023.7971>,\n",
       "  <tf.Tensor: shape=(), dtype=float32, numpy=-3124.0493>],\n",
       " [<tf.Tensor: shape=(), dtype=float32, numpy=-2250.6704>,\n",
       "  <tf.Tensor: shape=(), dtype=float32, numpy=-3453.9634>],\n",
       " [<tf.Tensor: shape=(), dtype=float32, numpy=-2480.7556>,\n",
       "  <tf.Tensor: shape=(), dtype=float32, numpy=-3780.9255>],\n",
       " [<tf.Tensor: shape=(), dtype=float32, numpy=-2663.591>,\n",
       "  <tf.Tensor: shape=(), dtype=float32, numpy=-4128.274>],\n",
       " [<tf.Tensor: shape=(), dtype=float32, numpy=-2854.0374>,\n",
       "  <tf.Tensor: shape=(), dtype=float32, numpy=-4426.729>],\n",
       " [<tf.Tensor: shape=(), dtype=float32, numpy=-3042.718>,\n",
       "  <tf.Tensor: shape=(), dtype=float32, numpy=-4679.6787>],\n",
       " [<tf.Tensor: shape=(), dtype=float32, numpy=-3197.6943>,\n",
       "  <tf.Tensor: shape=(), dtype=float32, numpy=-4866.3486>],\n",
       " [<tf.Tensor: shape=(), dtype=float32, numpy=-3343.73>,\n",
       "  <tf.Tensor: shape=(), dtype=float32, numpy=-5021.669>],\n",
       " [<tf.Tensor: shape=(), dtype=float32, numpy=-3434.9768>,\n",
       "  <tf.Tensor: shape=(), dtype=float32, numpy=-5112.5396>],\n",
       " [<tf.Tensor: shape=(), dtype=float32, numpy=-3444.511>,\n",
       "  <tf.Tensor: shape=(), dtype=float32, numpy=-5135.3984>],\n",
       " [<tf.Tensor: shape=(), dtype=float32, numpy=-3414.0042>,\n",
       "  <tf.Tensor: shape=(), dtype=float32, numpy=-5108.094>],\n",
       " [<tf.Tensor: shape=(), dtype=float32, numpy=-3324.2222>,\n",
       "  <tf.Tensor: shape=(), dtype=float32, numpy=-5036.4844>],\n",
       " [<tf.Tensor: shape=(), dtype=float32, numpy=-3187.1216>,\n",
       "  <tf.Tensor: shape=(), dtype=float32, numpy=-4944.873>],\n",
       " [<tf.Tensor: shape=(), dtype=float32, numpy=-3027.4792>,\n",
       "  <tf.Tensor: shape=(), dtype=float32, numpy=-4830.397>],\n",
       " [<tf.Tensor: shape=(), dtype=float32, numpy=-2833.8982>,\n",
       "  <tf.Tensor: shape=(), dtype=float32, numpy=-4732.4585>],\n",
       " [<tf.Tensor: shape=(), dtype=float32, numpy=-2634.4285>,\n",
       "  <tf.Tensor: shape=(), dtype=float32, numpy=-4664.8467>],\n",
       " [<tf.Tensor: shape=(), dtype=float32, numpy=-2452.0088>,\n",
       "  <tf.Tensor: shape=(), dtype=float32, numpy=-4562.4263>],\n",
       " [<tf.Tensor: shape=(), dtype=float32, numpy=-2267.5864>,\n",
       "  <tf.Tensor: shape=(), dtype=float32, numpy=-4441.137>],\n",
       " [<tf.Tensor: shape=(), dtype=float32, numpy=-2045.6877>,\n",
       "  <tf.Tensor: shape=(), dtype=float32, numpy=-4307.7334>],\n",
       " [<tf.Tensor: shape=(), dtype=float32, numpy=-1820.3822>,\n",
       "  <tf.Tensor: shape=(), dtype=float32, numpy=-4187.878>],\n",
       " [<tf.Tensor: shape=(), dtype=float32, numpy=-1595.053>,\n",
       "  <tf.Tensor: shape=(), dtype=float32, numpy=-4079.3923>],\n",
       " [<tf.Tensor: shape=(), dtype=float32, numpy=-1394.0951>,\n",
       "  <tf.Tensor: shape=(), dtype=float32, numpy=-3921.5945>],\n",
       " [<tf.Tensor: shape=(), dtype=float32, numpy=-1153.3462>,\n",
       "  <tf.Tensor: shape=(), dtype=float32, numpy=-3751.36>],\n",
       " [<tf.Tensor: shape=(), dtype=float32, numpy=-875.5279>,\n",
       "  <tf.Tensor: shape=(), dtype=float32, numpy=-3563.0757>],\n",
       " [<tf.Tensor: shape=(), dtype=float32, numpy=-639.22485>,\n",
       "  <tf.Tensor: shape=(), dtype=float32, numpy=-3341.8755>],\n",
       " [<tf.Tensor: shape=(), dtype=float32, numpy=-437.13318>,\n",
       "  <tf.Tensor: shape=(), dtype=float32, numpy=-3032.3213>],\n",
       " [<tf.Tensor: shape=(), dtype=float32, numpy=-249.05423>,\n",
       "  <tf.Tensor: shape=(), dtype=float32, numpy=-2705.1482>],\n",
       " [<tf.Tensor: shape=(), dtype=float32, numpy=340.7317>,\n",
       "  <tf.Tensor: shape=(), dtype=float32, numpy=-1326.9166>],\n",
       " [<tf.Tensor: shape=(), dtype=float32, numpy=501.50787>,\n",
       "  <tf.Tensor: shape=(), dtype=float32, numpy=-1059.1943>],\n",
       " [<tf.Tensor: shape=(), dtype=float32, numpy=633.50903>,\n",
       "  <tf.Tensor: shape=(), dtype=float32, numpy=-816.6628>],\n",
       " [<tf.Tensor: shape=(), dtype=float32, numpy=730.2911>,\n",
       "  <tf.Tensor: shape=(), dtype=float32, numpy=-594.65607>],\n",
       " [<tf.Tensor: shape=(), dtype=float32, numpy=818.15137>,\n",
       "  <tf.Tensor: shape=(), dtype=float32, numpy=-390.03082>],\n",
       " [<tf.Tensor: shape=(), dtype=float32, numpy=905.8832>,\n",
       "  <tf.Tensor: shape=(), dtype=float32, numpy=-184.57521>],\n",
       " [<tf.Tensor: shape=(), dtype=float32, numpy=1009.07275>,\n",
       "  <tf.Tensor: shape=(), dtype=float32, numpy=15.761974>],\n",
       " [<tf.Tensor: shape=(), dtype=float32, numpy=1085.4039>,\n",
       "  <tf.Tensor: shape=(), dtype=float32, numpy=248.42737>],\n",
       " [<tf.Tensor: shape=(), dtype=float32, numpy=970.37866>,\n",
       "  <tf.Tensor: shape=(), dtype=float32, numpy=591.9403>],\n",
       " [<tf.Tensor: shape=(), dtype=float32, numpy=958.2058>,\n",
       "  <tf.Tensor: shape=(), dtype=float32, numpy=800.6876>],\n",
       " [<tf.Tensor: shape=(), dtype=float32, numpy=933.8443>,\n",
       "  <tf.Tensor: shape=(), dtype=float32, numpy=956.4834>],\n",
       " [<tf.Tensor: shape=(), dtype=float32, numpy=914.60986>,\n",
       "  <tf.Tensor: shape=(), dtype=float32, numpy=1089.4501>],\n",
       " [<tf.Tensor: shape=(), dtype=float32, numpy=889.1229>,\n",
       "  <tf.Tensor: shape=(), dtype=float32, numpy=1206.284>],\n",
       " [<tf.Tensor: shape=(), dtype=float32, numpy=841.57227>,\n",
       "  <tf.Tensor: shape=(), dtype=float32, numpy=1309.9873>],\n",
       " [<tf.Tensor: shape=(), dtype=float32, numpy=789.52954>,\n",
       "  <tf.Tensor: shape=(), dtype=float32, numpy=1390.475>],\n",
       " [<tf.Tensor: shape=(), dtype=float32, numpy=735.5962>,\n",
       "  <tf.Tensor: shape=(), dtype=float32, numpy=1446.9485>],\n",
       " [<tf.Tensor: shape=(), dtype=float32, numpy=661.1772>,\n",
       "  <tf.Tensor: shape=(), dtype=float32, numpy=1467.9067>],\n",
       " [<tf.Tensor: shape=(), dtype=float32, numpy=585.1359>,\n",
       "  <tf.Tensor: shape=(), dtype=float32, numpy=1487.4043>],\n",
       " [<tf.Tensor: shape=(), dtype=float32, numpy=147.74889>,\n",
       "  <tf.Tensor: shape=(), dtype=float32, numpy=1998.9773>],\n",
       " [<tf.Tensor: shape=(), dtype=float32, numpy=36.993935>,\n",
       "  <tf.Tensor: shape=(), dtype=float32, numpy=1944.8582>],\n",
       " [<tf.Tensor: shape=(), dtype=float32, numpy=-146.62935>,\n",
       "  <tf.Tensor: shape=(), dtype=float32, numpy=985.8222>],\n",
       " [<tf.Tensor: shape=(), dtype=float32, numpy=-233.87135>,\n",
       "  <tf.Tensor: shape=(), dtype=float32, numpy=913.34644>],\n",
       " [<tf.Tensor: shape=(), dtype=float32, numpy=-318.95004>,\n",
       "  <tf.Tensor: shape=(), dtype=float32, numpy=846.6941>],\n",
       " [<tf.Tensor: shape=(), dtype=float32, numpy=-368.57596>,\n",
       "  <tf.Tensor: shape=(), dtype=float32, numpy=789.50244>],\n",
       " [<tf.Tensor: shape=(), dtype=float32, numpy=-395.97794>,\n",
       "  <tf.Tensor: shape=(), dtype=float32, numpy=738.7459>],\n",
       " [<tf.Tensor: shape=(), dtype=float32, numpy=-423.60635>,\n",
       "  <tf.Tensor: shape=(), dtype=float32, numpy=688.1255>],\n",
       " [<tf.Tensor: shape=(), dtype=float32, numpy=-722.1287>,\n",
       "  <tf.Tensor: shape=(), dtype=float32, numpy=779.28815>],\n",
       " [<tf.Tensor: shape=(), dtype=float32, numpy=-792.9936>,\n",
       "  <tf.Tensor: shape=(), dtype=float32, numpy=677.7851>],\n",
       " [<tf.Tensor: shape=(), dtype=float32, numpy=-845.65753>,\n",
       "  <tf.Tensor: shape=(), dtype=float32, numpy=575.71454>],\n",
       " [<tf.Tensor: shape=(), dtype=float32, numpy=-880.1235>,\n",
       "  <tf.Tensor: shape=(), dtype=float32, numpy=468.94025>],\n",
       " [<tf.Tensor: shape=(), dtype=float32, numpy=-906.1093>,\n",
       "  <tf.Tensor: shape=(), dtype=float32, numpy=358.2533>],\n",
       " [<tf.Tensor: shape=(), dtype=float32, numpy=-931.83813>,\n",
       "  <tf.Tensor: shape=(), dtype=float32, numpy=263.7906>],\n",
       " [<tf.Tensor: shape=(), dtype=float32, numpy=-1296.528>,\n",
       "  <tf.Tensor: shape=(), dtype=float32, numpy=-246.17339>],\n",
       " [<tf.Tensor: shape=(), dtype=float32, numpy=-1304.1676>,\n",
       "  <tf.Tensor: shape=(), dtype=float32, numpy=-313.70026>],\n",
       " [<tf.Tensor: shape=(), dtype=float32, numpy=-1306.5385>,\n",
       "  <tf.Tensor: shape=(), dtype=float32, numpy=-371.80762>],\n",
       " [<tf.Tensor: shape=(), dtype=float32, numpy=-1299.8035>,\n",
       "  <tf.Tensor: shape=(), dtype=float32, numpy=-424.6656>],\n",
       " [<tf.Tensor: shape=(), dtype=float32, numpy=-1283.5142>,\n",
       "  <tf.Tensor: shape=(), dtype=float32, numpy=-469.82257>],\n",
       " [<tf.Tensor: shape=(), dtype=float32, numpy=-1266.7311>,\n",
       "  <tf.Tensor: shape=(), dtype=float32, numpy=-511.06415>]]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def denormalize_stroke(stroke, drawing):\n",
    "    denormalized_stroke = []\n",
    "\n",
    "    minx, miny, maxx, maxy = get_bounding_box(drawing)\n",
    "    width, height = maxx - minx, maxy - miny\n",
    "\n",
    "\n",
    "    for x_norm, y_norm in stroke:\n",
    "        x = (x_norm * width) + minx\n",
    "        y = (y_norm * height) + miny\n",
    "        denormalized_stroke.append([x, y])\n",
    "    return denormalized_stroke\n",
    "\n",
    "\n",
    "stroke_original = denormalize_stroke(decode_stroke_result[\"stroke\"][0], sample_drawing)\n",
    "\n",
    "stroke_original"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try forward pass signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ConcreteFunction (*, input_seq_len: TensorSpec(shape=(None,), dtype=tf.int32, name='input_seq_len'), input_stroke: TensorSpec(shape=(None, None, 3), dtype=tf.float32, name='input_stroke'), target_seq_len: TensorSpec(shape=(), dtype=tf.int32, name='target_seq_len')) -> Dict[['pen', TensorSpec(shape=(None, None, 1), dtype=tf.float32, name='pen')], ['embedding_sample', TensorSpec(shape=(None, 8), dtype=tf.float32, name='embedding_sample')], ['seq_len', TensorSpec(shape=(None,), dtype=tf.int32, name='seq_len')], ['stroke', TensorSpec(shape=(None, None, 2), dtype=tf.float32, name='stroke')]] at 0x30E37E970>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward_pass = model.signatures[\"forward_pass\"]\n",
    "forward_pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__ConcatV2_N_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} ConcatOp : Dimension 1 in both shapes must be equal: shape[0] = [1,41,3] vs. shape[1] = [1,95,3] [Op:ConcatV2] name: concat",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[125], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Convert lists to tensors with the right shape\u001b[39;00m\n\u001b[1;32m     11\u001b[0m input_seq_len_tensor \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(input_seq_len_list, dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mint32)\n\u001b[0;32m---> 12\u001b[0m input_stroke_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_stroke_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Add batch dimension\u001b[39;00m\n\u001b[1;32m     15\u001b[0m input_seq_len_tensor \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mexpand_dims(input_seq_len_tensor, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# Shape: (1, num_strokes, 2)\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-TheUniversityofChicago/Thesis/.venv/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-TheUniversityofChicago/Thesis/.venv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:5883\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   5881\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NoReturn:\n\u001b[1;32m   5882\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m-> 5883\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__ConcatV2_N_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} ConcatOp : Dimension 1 in both shapes must be equal: shape[0] = [1,41,3] vs. shape[1] = [1,95,3] [Op:ConcatV2] name: concat"
     ]
    }
   ],
   "source": [
    "input_seq_len_list = []\n",
    "input_stroke_list = []\n",
    "\n",
    "# Process only the first two strokes\n",
    "for stroke in drawing_resampled[:2]:\n",
    "    input_seq_len_tensor, input_stroke_tensor = formalize_input(stroke)\n",
    "    input_seq_len_list.append(input_seq_len_tensor)\n",
    "    input_stroke_list.append(input_stroke_tensor)\n",
    "\n",
    "# Convert lists to tensors with the right shape\n",
    "input_seq_len_tensor = tf.convert_to_tensor(input_seq_len_list, dtype=tf.int32)\n",
    "input_stroke_tensor = tf.concat(input_stroke_list, axis=0)\n",
    "\n",
    "# Add batch dimension\n",
    "input_seq_len_tensor = tf.expand_dims(input_seq_len_tensor, axis=0)  # Shape: (1, num_strokes, 2)\n",
    "# inp_embeddings_tensor = tf.expand_dims(inp_embeddings_tensor, axis=0)  # Shape: (1, num_strokes, 8)\n",
    "\n",
    "\n",
    "# forward_pass(input_seq_len=input_seq_len_tensor, input_stroke=input_stroke_tensor,\n",
    "#              target_seq_len = target_seq_len_tensor)\n",
    "\n",
    "input_seq_len_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Try Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def process_drawing_for_encode_stroke(drawing):\n",
    "#     flat_strokes = []\n",
    "#     total_points = 0\n",
    "#     for stroke in drawing:\n",
    "#         for i in range(len(stroke[0])):  # Iterate through points in the stroke\n",
    "#             x = stroke[0][i]\n",
    "#             y = stroke[1][i]\n",
    "#             # Assuming the third list contains timing information, not directly used here\n",
    "#             # If there's a specific \"pen state\" value needed, adjust accordingly\n",
    "#             flat_strokes.append([x, y, 1])  # Use '1' as a placeholder for pen state\n",
    "#         total_points += len(stroke[0])\n",
    "    \n",
    "#     # Convert to tensors\n",
    "#     input_stroke = tf.constant(flat_strokes, dtype=tf.float32)\n",
    "#     input_seq_len = tf.constant([total_points], dtype=tf.int32)\n",
    "    \n",
    "#     return input_stroke, input_seq_len\n",
    "\n",
    "# # Find the maximum sequence length across all processed drawings\n",
    "# max_seq_len = max(input_stroke.shape[0] for input_stroke, _ in processed_drawings)\n",
    "\n",
    "# # Pad each drawing sequence to the maximum length\n",
    "# padded_drawings = []\n",
    "# for input_stroke, input_seq_len in processed_drawings:\n",
    "#     # Calculate the padding amounts\n",
    "#     padding = [[0, max_seq_len - tf.shape(input_stroke)[0]], [0, 0]]  # Pad the sequence length to max_seq_len\n",
    "    \n",
    "#     # Pad the stroke data\n",
    "#     padded_stroke = tf.pad(input_stroke, padding, \"CONSTANT\")\n",
    "    \n",
    "#     # Append the padded stroke and original sequence length\n",
    "#     padded_drawings.append((padded_stroke, input_seq_len))\n",
    "\n",
    "# padded_drawings\n",
    "\n",
    "# import json\n",
    "\n",
    "# processed_drawings = []\n",
    "\n",
    "# # Draw a sample of 320 sketches\n",
    "# max_rows = 320\n",
    "# current_row = 0\n",
    "\n",
    "# with open(\"data_dir/quick_draw/raw_Eiffel_Tower.ndjson\", 'r') as f:\n",
    "#     for line in f:\n",
    "#         if current_row < max_rows:\n",
    "#             drawing_data = json.loads(line)\n",
    "#             drawing = drawing_data[\"drawing\"]\n",
    "#             processed_drawing = process_drawing_for_encode_stroke(drawing)\n",
    "#             processed_drawings.append(processed_drawing)\n",
    "#             current_row += 1\n",
    "#         else:\n",
    "#             break\n",
    "# stroke_tensors = [x[0] for x in padded_drawings]\n",
    "# seq_len_tensors = [x[1] for x in padded_drawings]\n",
    "\n",
    "# stroke_dataset = tf.data.Dataset.from_tensor_slices(stroke_tensors)\n",
    "# seq_len_dataset = tf.data.Dataset.from_tensor_slices(seq_len_tensors)\n",
    "\n",
    "# # Combine into a single dataset\n",
    "# dataset = tf.data.Dataset.zip((stroke_dataset, seq_len_dataset))\n",
    "\n",
    "# dataset\n",
    "\n",
    "# # Set your desired batch size\n",
    "# batch_size = 128\n",
    "\n",
    "# # Batch the dataset. No need to specify padding values or shapes here because\n",
    "# # your tensors within each dataset element already have a uniform shape after padding.\n",
    "# batched_dataset = dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the features of importance for input formatting\n",
    "# feature_description = {\n",
    "#     'ink': tf.io.VarLenFeature(tf.float32),\n",
    "# }\n",
    "\n",
    "# # For now, I use a very small sample of dataset\n",
    "# file_paths = \"data_dir/quick_draw/training/raw_Eiffel_Tower-00000-of-00010\"\n",
    "# dataset = tf.data.TFRecordDataset(file_paths)\n",
    "\n",
    "# # for raw_record in dataset.take(1):\n",
    "# #   example = tf.train.Example()\n",
    "# #   example.ParseFromString(raw_record.numpy())\n",
    "# #   print(example)\n",
    "\n",
    "# # Parse a Tensorflow Example proto \n",
    "# parsed_dataset = dataset.map(lambda x: tf.io.parse_single_example(x, feature_description)) \n",
    "\n",
    "# # Define a function to get the `input_seq_len` and `input_stroke` arguments \n",
    "# # for fitting the pretrained model (specifically, `encode_stroke` signature)\n",
    "# max_length_threshold = 201\n",
    "\n",
    "# def get_input_arguments(parsed_record):\n",
    "#     # Reshape and extract the first three dimensions from parsed_record['ink']\n",
    "#     # (x coordinate, y coordinate, and pen state)\n",
    "#     ink = tf.sparse.to_dense(parsed_record['ink'])\n",
    "#     input_seq_len = tf.shape(ink)[0] // 4\n",
    "#     ink_reshaped = tf.reshape(ink, (input_seq_len, 4))\n",
    "#     # Expand the input_stroke to three dimensions for batching \n",
    "#     input_stroke = tf.expand_dims(ink_reshaped[:, :3], axis=0)\n",
    "    \n",
    "#     # Make sure it matches the input shape \n",
    "#     input_seq_len = tf.reshape(input_seq_len, [1]) \n",
    "\n",
    "#     return input_seq_len, input_stroke\n",
    "    \n",
    "# preprocessed_dataset = parsed_dataset.map(get_input_arguments)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
